{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Model Configuration: Default model type set to 'optimized'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dxcam_cpp as dxcam\n",
    "from src.utils.windowtools import (\n",
    "    fuzzy_window_search,\n",
    "    calculate_aspect_ratio,\n",
    "    check_aspect_ratio_validity,\n",
    "    get_monitor_number_from_coords,\n",
    "    normalise_coords_to_monitor\n",
    ")\n",
    "from src.utils.helpers import (\n",
    "    pre_process,\n",
    "    pre_process_distbox,\n",
    ")\n",
    "from src.models import get_model, get_default_model_type, get_model_info\n",
    "import matplotlib.pyplot as plt\n",
    "from easyocr import Reader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import threading\n",
    "import time as systime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 2560, 1392)]\n",
      "1\n",
      "The aspect ratio is reasonable.\n",
      "(0, 0, 2560, 1392)\n"
     ]
    }
   ],
   "source": [
    "coords = fuzzy_window_search(\"asphalt\")\n",
    "\n",
    "monitor_id = get_monitor_number_from_coords(coords)\n",
    "\n",
    "normalised_coords = normalise_coords_to_monitor(coords, monitor_id)\n",
    "\n",
    "aspect_ratio = calculate_aspect_ratio(normalised_coords)\n",
    "\n",
    "check_aspect_ratio_validity(aspect_ratio)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "camera = dxcam.create(device_idx=0, output_idx=monitor_id)\n",
    "capturing = True\n",
    "time = 0\n",
    "elapsed_ms = 0\n",
    "percentage = 0\n",
    "\n",
    "# Inference time tracking\n",
    "inference_times = []\n",
    "total_loops = 0\n",
    "avg_inference_time = 0\n",
    "\n",
    "reader = Reader(['en'], gpu=True)  # Still needed for DIST detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a frame from the camera\n",
    "window = camera.grab()\n",
    "\n",
    "# Extract coordinates from the coords variable\n",
    "x1, y1, x2, y2 = normalised_coords\n",
    "\n",
    "capture_coords = (x1, y1, x2, int(y1 + (y2 - y1) / 3.4))\n",
    "\n",
    "camera.start(region=capture_coords, target_fps=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_capturing():\n",
    "    global capturing\n",
    "    capturing = True\n",
    "\n",
    "def stop_capturing():\n",
    "    global capturing\n",
    "    capturing = False\n",
    "\n",
    "def toggle_pin():\n",
    "    global root, is_pinned\n",
    "    is_pinned = not is_pinned\n",
    "    if is_pinned:\n",
    "        root.wm_attributes(\"-topmost\", True)\n",
    "        pin_button.config(text=\"üìå Unpin\", bg=\"#ff6b6b\")\n",
    "    else:\n",
    "        root.wm_attributes(\"-topmost\", False)\n",
    "        pin_button.config(text=\"üìå Pin\", bg=\"#4ecdc4\")\n",
    "\n",
    "def update_ui():\n",
    "    global time, elapsed_ms, percentage, avg_inference_time, inference_times\n",
    "    \n",
    "    # Update labels efficiently (only if values changed)\n",
    "    time_label.config(text=f\"Time: {time}\")\n",
    "    elapsed_label.config(text=f\"Loop: {elapsed_ms:.1f}ms\")\n",
    "    \n",
    "    # Smart status display\n",
    "    if percentage and percentage != \"0%\":\n",
    "        percentage_label.config(text=f\"Distance: {percentage}\", fg=\"#2ecc71\")\n",
    "        status_label.config(text=\"üèÅ Race in progress\", fg=\"#2ecc71\")\n",
    "    else:\n",
    "        percentage_label.config(text=\"Distance: --\", fg=\"#95a5a6\")\n",
    "        status_label.config(text=\"‚è∏Ô∏è Race not in progress\", fg=\"#95a5a6\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    if inference_times:\n",
    "        current_inference = inference_times[-1] if inference_times else 0\n",
    "        inference_label.config(text=f\"Inference: {current_inference:.1f}ms\")\n",
    "        avg_inference_label.config(text=f\"Avg: {avg_inference_time:.1f}ms\")\n",
    "    else:\n",
    "        inference_label.config(text=\"Inference: --\")\n",
    "        avg_inference_label.config(text=\"Avg: --\")\n",
    "    \n",
    "    # Schedule next update (reduced frequency to avoid performance impact)\n",
    "    root.after(150, update_ui)\n",
    "\n",
    "def create_ui():\n",
    "    global root, time_label, elapsed_label, percentage_label, status_label\n",
    "    global avg_inference_label, inference_label, pin_button, is_pinned\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.title(\"ALU Timing Tool\")\n",
    "    root.geometry(\"280x320\")\n",
    "    root.resizable(False, False)\n",
    "    \n",
    "    # Set up the window style\n",
    "    root.configure(bg=\"#2c3e50\")\n",
    "    is_pinned = False\n",
    "    \n",
    "    # Header with pin button\n",
    "    header_frame = tk.Frame(root, bg=\"#2c3e50\")\n",
    "    header_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "    \n",
    "    title_label = tk.Label(header_frame, text=\"ALU Timing Tool\", \n",
    "                          font=(\"Helvetica\", 12, \"bold\"), fg=\"#ecf0f1\", bg=\"#2c3e50\")\n",
    "    title_label.pack(side=\"left\")\n",
    "    \n",
    "    pin_button = tk.Button(header_frame, text=\"üìå Pin\", command=toggle_pin, \n",
    "                          bg=\"#4ecdc4\", fg=\"white\", font=(\"Helvetica\", 8),\n",
    "                          relief=\"flat\", padx=8, pady=2)\n",
    "    pin_button.pack(side=\"right\")\n",
    "    \n",
    "    # Control buttons\n",
    "    button_frame = tk.Frame(root, bg=\"#2c3e50\")\n",
    "    button_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "    \n",
    "    start_button = tk.Button(button_frame, text=\"‚ñ∂Ô∏è Start\", command=start_capturing, \n",
    "                            bg=\"#27ae60\", fg=\"white\", font=(\"Helvetica\", 11, \"bold\"),\n",
    "                            relief=\"flat\", padx=15, pady=8)\n",
    "    start_button.pack(side=\"left\", padx=(0, 5), fill=\"x\", expand=True)\n",
    "\n",
    "    stop_button = tk.Button(button_frame, text=\"‚èπÔ∏è Stop\", command=stop_capturing, \n",
    "                           bg=\"#e74c3c\", fg=\"white\", font=(\"Helvetica\", 11, \"bold\"),\n",
    "                           relief=\"flat\", padx=15, pady=8)\n",
    "    stop_button.pack(side=\"right\", padx=(5, 0), fill=\"x\", expand=True)\n",
    "    \n",
    "    # Status section\n",
    "    status_frame = tk.Frame(root, bg=\"#34495e\", relief=\"flat\", bd=1)\n",
    "    status_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "    \n",
    "    status_label = tk.Label(status_frame, text=\"‚è∏Ô∏è Race not in progress\", \n",
    "                           font=(\"Helvetica\", 10, \"bold\"), fg=\"#95a5a6\", bg=\"#34495e\")\n",
    "    status_label.pack(pady=8)\n",
    "    \n",
    "    # Main metrics\n",
    "    metrics_frame = tk.Frame(root, bg=\"#2c3e50\")\n",
    "    metrics_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "    \n",
    "    # Time (placeholder for future use)\n",
    "    time_label = tk.Label(metrics_frame, text=f\"Time: {time}\", \n",
    "                         font=(\"Helvetica\", 10), fg=\"#ecf0f1\", bg=\"#2c3e50\")\n",
    "    time_label.pack(anchor=\"w\", pady=2)\n",
    "    \n",
    "    # Distance percentage\n",
    "    percentage_label = tk.Label(metrics_frame, text=\"Distance: --\", \n",
    "                               font=(\"Helvetica\", 11, \"bold\"), fg=\"#95a5a6\", bg=\"#2c3e50\")\n",
    "    percentage_label.pack(anchor=\"w\", pady=2)\n",
    "    \n",
    "    # Performance section\n",
    "    perf_frame = tk.Frame(root, bg=\"#34495e\", relief=\"flat\", bd=1)\n",
    "    perf_frame.pack(fill=\"x\", padx=10, pady=5)\n",
    "    \n",
    "    perf_title = tk.Label(perf_frame, text=\"Performance\", \n",
    "                         font=(\"Helvetica\", 9, \"bold\"), fg=\"#bdc3c7\", bg=\"#34495e\")\n",
    "    perf_title.pack(anchor=\"w\", padx=8, pady=(5, 0))\n",
    "    \n",
    "    # Loop timing\n",
    "    elapsed_label = tk.Label(perf_frame, text=f\"Loop: {elapsed_ms:.1f}ms\", \n",
    "                            font=(\"Helvetica\", 9), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    elapsed_label.pack(anchor=\"w\", padx=8, pady=1)\n",
    "    \n",
    "    # Inference timing\n",
    "    inference_label = tk.Label(perf_frame, text=\"Inference: --\", \n",
    "                              font=(\"Helvetica\", 9), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    inference_label.pack(anchor=\"w\", padx=8, pady=1)\n",
    "    \n",
    "    avg_inference_label = tk.Label(perf_frame, text=\"Avg: --\", \n",
    "                                  font=(\"Helvetica\", 9), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    avg_inference_label.pack(anchor=\"w\", padx=8, pady=(1, 5))\n",
    "    \n",
    "    # Start the UI update loop\n",
    "    update_ui()\n",
    "    \n",
    "    # Make the window appear on top initially\n",
    "    root.lift()\n",
    "    root.focus_force()\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "# Initialize UI state variables\n",
    "is_pinned = False\n",
    "root = None\n",
    "\n",
    "ui_thread = threading.Thread(target=create_ui, daemon=True)\n",
    "ui_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Using device: cuda\n",
      "üìã Using default model type: 'optimized'\n",
      "Successfully loaded optimized model with optimized weights on cuda.\n",
      "Model architecture: OptimizedPercentageCNN\n",
      "Model device: cuda:0\n",
      "‚úÖ Enabled cuDNN benchmark mode\n",
      "‚úÖ Disabled gradient computation\n",
      "‚úÖ Model compiled with TorchScript\n",
      "‚úÖ Model warmed up\n",
      "‚úÖ Cleared CUDA cache\n",
      "üèÅ Model loading and optimization complete!\n",
      "‚úÖ Model warmed up\n",
      "‚úÖ Cleared CUDA cache\n",
      "üèÅ Model loading and optimization complete!\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Trained Model using centralized system ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîß Using device: {device}\")\n",
    "\n",
    "# Try to load the configured model first, with fallback options\n",
    "model = None\n",
    "model_name = \"unknown\"\n",
    "\n",
    "try:\n",
    "    # First try the centralized model system\n",
    "    model = get_model()\n",
    "    model_name = get_default_model_type()\n",
    "    \n",
    "    # Try to load the optimized model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('percentage_cnn_optimized.pth', map_location=device))\n",
    "        print(f\"Successfully loaded {model_name} model with optimized weights on {device}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Optimized weights not found, trying legacy weights...\")\n",
    "        model.load_state_dict(torch.load('percentage_cnn.pth', map_location=device))\n",
    "        print(f\"Successfully loaded {model_name} model with legacy weights on {device}.\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to load centralized model: {e}\")\n",
    "    \n",
    "    # Fallback to hardcoded model loading\n",
    "    try:\n",
    "        # Legacy SimpleCNN fallback\n",
    "        class SimpleCNN(nn.Module):\n",
    "            def __init__(self, num_classes=100):\n",
    "                super(SimpleCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "                self.fc1 = nn.Linear(32 * 16 * 16, 512)\n",
    "                self.fc2 = nn.Linear(512, num_classes)\n",
    "                self.relu = nn.ReLU()\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.conv1(x)))\n",
    "                x = self.pool(self.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 32 * 16 * 16)\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "        \n",
    "        model = SimpleCNN(num_classes=100).to(device)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('percentage_cnn_optimized.pth', map_location=device))\n",
    "            model_name = \"SimpleCNN (fallback with optimized weights)\"\n",
    "        except FileNotFoundError:\n",
    "            model.load_state_dict(torch.load('percentage_cnn.pth', map_location=device))\n",
    "            model_name = \"SimpleCNN (fallback with legacy weights)\"\n",
    "        print(f\"Successfully loaded fallback model on {device}.\")\n",
    "    except Exception as fallback_error:\n",
    "        print(f\"Fallback model loading also failed: {fallback_error}\")\n",
    "        print(\"Error: No model could be loaded. Please ensure model files are available.\")\n",
    "        model = None\n",
    "\n",
    "if model is not None:\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(f\"Model architecture: {model.__class__.__name__}\")\n",
    "    print(f\"Model device: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # üöÄ PERFORMANCE OPTIMIZATIONS üöÄ\n",
    "    \n",
    "    # 1. Enable cudnn benchmarking for consistent convolution algorithms\n",
    "    if device.type == 'cuda':\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "        print(\"‚úÖ Enabled cuDNN benchmark mode\")\n",
    "    \n",
    "    # 2. Disable gradient computation globally (already in eval mode, but this is extra)\n",
    "    torch.set_grad_enabled(False)\n",
    "    print(\"‚úÖ Disabled gradient computation\")\n",
    "    \n",
    "    # 3. Try to compile the model with torch.jit for optimization\n",
    "    try:\n",
    "        # Create a dummy input for scripting\n",
    "        dummy_input = torch.randn(1, 1, 64, 64).to(device)\n",
    "        model = torch.jit.script(model)\n",
    "        print(\"‚úÖ Model compiled with TorchScript\")\n",
    "        \n",
    "        # Warm up the compiled model\n",
    "        for _ in range(5):\n",
    "            with torch.no_grad():\n",
    "                _ = model(dummy_input)\n",
    "        print(\"‚úÖ Model warmed up\")\n",
    "        \n",
    "    except Exception as jit_error:\n",
    "        print(f\"‚ö†Ô∏è TorchScript compilation failed: {jit_error}\")\n",
    "        print(\"   Continuing with eager mode...\")\n",
    "    \n",
    "    # 4. Set memory allocation strategy\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"‚úÖ Cleared CUDA cache\")\n",
    "\n",
    "# --- Define Image Transforms ---\n",
    "# These must be the same as the transforms used during training\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "print(\"üèÅ Model loading and optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_loop():\n",
    "    global dist_box, capturing, textarray, camera, percentage, elapsed_ms, total_loops\n",
    "\n",
    "    # Start the loop\n",
    "    while capturing:\n",
    "        if capturing:\n",
    "            start_time = systime.perf_counter()\n",
    "            total_loops += 1\n",
    "            \n",
    "            # Initialize cnn_result to avoid UnboundLocalError\n",
    "            cnn_result = None\n",
    "            \n",
    "            window = camera.get_latest_frame()\n",
    "            height, width, _ = window.shape\n",
    "            top_right_region = window[50:height, 0:int(width * 0.35)]\n",
    "\n",
    "            if dist_box is None:\n",
    "                preprocessed_region = pre_process(top_right_region)\n",
    "                results = reader.readtext(preprocessed_region)\n",
    "                \n",
    "                dist_found = False\n",
    "                dist_bbox = None\n",
    "                dist_index = -1\n",
    "                \n",
    "                # Find DIST\n",
    "                for i, (bbox, text, confidence) in enumerate(results):\n",
    "                    if \"dist\" in text.lower() and not dist_found:\n",
    "                        dist_bbox = np.array(bbox)\n",
    "                        dist_index = i\n",
    "                        dist_found = True\n",
    "                \n",
    "                # If we found DIST, look for percentage\n",
    "                if dist_found:\n",
    "                    dist_x0, dist_y0 = np.min(dist_bbox[:, 0]), np.min(dist_bbox[:, 1])\n",
    "                    dist_x1, dist_y1 = np.max(dist_bbox[:, 0]), np.max(dist_bbox[:, 1])\n",
    "                    dist_center_y = (dist_y0 + dist_y1) / 2\n",
    "                    \n",
    "                    best_percentage_match = None\n",
    "                    best_score = 0\n",
    "                    \n",
    "                    # Look for percentage indicators with more flexible criteria\n",
    "                    for j, (bbox, text, confidence) in enumerate(results):\n",
    "                        if j == dist_index:  # Skip the DIST box itself\n",
    "                            continue\n",
    "                            \n",
    "                        bbox_array = np.array(bbox)\n",
    "                        nx0, ny0 = np.min(bbox_array[:, 0]), np.min(bbox_array[:, 1])\n",
    "                        nx1, ny1 = np.max(bbox_array[:, 0]), np.max(bbox_array[:, 1])\n",
    "                        bbox_center_y = (ny0 + ny1) / 2\n",
    "                        \n",
    "                        # More flexible matching criteria\n",
    "                        text_clean = text.strip().replace(' ', '').replace(',', '').replace('.', '')\n",
    "                        \n",
    "                        # Check if it looks like a percentage\n",
    "                        has_percent = '%' in text_clean\n",
    "                        has_numbers = any(char.isdigit() for char in text_clean)\n",
    "                        ends_with_7 = text_clean.endswith('7')  # Sometimes % is read as 7\n",
    "                        \n",
    "                        # Position criteria (more flexible)\n",
    "                        reasonable_y_distance = abs(bbox_center_y - dist_center_y) < 50\n",
    "                        to_the_right = nx0 > dist_x0\n",
    "                        reasonable_x_distance = (nx0 - dist_x1) < 200\n",
    "                        \n",
    "                        # Calculate a score for this match\n",
    "                        score = 0\n",
    "                        if has_percent:\n",
    "                            score += 50\n",
    "                        if has_numbers:\n",
    "                            score += 20\n",
    "                        if ends_with_7:\n",
    "                            score += 10\n",
    "                        if reasonable_y_distance:\n",
    "                            score += 30\n",
    "                        if to_the_right:\n",
    "                            score += 20\n",
    "                        if reasonable_x_distance:\n",
    "                            score += 10\n",
    "                        \n",
    "                        # Add confidence boost\n",
    "                        score += confidence * 10\n",
    "                        \n",
    "                        if score > best_score and score > 40:\n",
    "                            best_score = score\n",
    "                            best_percentage_match = (j, bbox, text, confidence)\n",
    "                    \n",
    "                    # If we found a good percentage match\n",
    "                    if best_percentage_match is not None:\n",
    "                        j, next_bbox, next_text, next_confidence = best_percentage_match\n",
    "                        \n",
    "                        # Calculate combined bounding box\n",
    "                        next_box = np.array(next_bbox)\n",
    "                        nx0, ny0 = np.min(next_box[:, 0]), np.min(next_box[:, 1])\n",
    "                        nx1, ny1 = np.max(next_box[:, 0]), np.max(next_box[:, 1])\n",
    "                        \n",
    "                        # Extend bounding box to include both with some padding\n",
    "                        x0 = int(min(dist_x0, nx0)) - 5\n",
    "                        y0 = int(min(dist_y0, ny0)) - 5\n",
    "                        x1 = int(max(dist_x1, nx1)) + 5\n",
    "                        y1 = int(max(dist_y1, ny1)) + 5\n",
    "                        \n",
    "                        # Ensure bounds are within image\n",
    "                        x0 = max(0, x0)\n",
    "                        y0 = max(0, y0)\n",
    "                        x1 = min(top_right_region.shape[1], x1)\n",
    "                        y1 = min(top_right_region.shape[0], y1)\n",
    "                    else:\n",
    "                        # Fallback: just use DIST box with some expansion\n",
    "                        x0 = int(dist_x0) - 10\n",
    "                        y0 = int(dist_y0) - 10\n",
    "                        x1 = int(dist_x1) + 100\n",
    "                        y1 = int(dist_y1) + 30\n",
    "                        \n",
    "                        # Ensure bounds are within image\n",
    "                        x0 = max(0, x0)\n",
    "                        y0 = max(0, y0)\n",
    "                        x1 = min(top_right_region.shape[1], x1)\n",
    "                        y1 = min(top_right_region.shape[0], y1)\n",
    "                    \n",
    "                    # Create the final bounding box\n",
    "                    dist_box = np.array([[x0, y0], [x1, y0], [x1, y1], [x0, y1]])\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # If we have the bounding box, crop the image\n",
    "            if dist_box is not None:\n",
    "                roi = top_right_region[int(dist_box[0][1]):int(dist_box[2][1]), int(dist_box[0][0]):int(dist_box[1][0])]\n",
    "                roi = roi[:, int(roi.shape[1] * 23 / 40):]\n",
    "\n",
    "                # Preprocess the cropped image for CNN\n",
    "                preprocessed_region = pre_process_distbox(roi, for_cnn=True)\n",
    "\n",
    "                # Use CNN for recognition\n",
    "                cnn_result = predict_with_cnn(preprocessed_region)\n",
    "\n",
    "            # Process CNN prediction\n",
    "            if cnn_result is not None:\n",
    "                predicted_percentage, confidence = cnn_result\n",
    "                \n",
    "                if confidence >= CONFIDENCE_THRESHOLD:\n",
    "                    percentage = f\"{predicted_percentage}%\"\n",
    "                else:\n",
    "                    dist_box = None\n",
    "                    percentage = \"\"\n",
    "            else:\n",
    "                dist_box = None\n",
    "                percentage = \"\"\n",
    "            \n",
    "            end_time = systime.perf_counter()\n",
    "            elapsed_ms = (end_time - start_time) * 1000\n",
    "\n",
    "            systime.sleep(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the main loop\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mthe_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mthe_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m height, width, _ = window.shape\n\u001b[32m     15\u001b[39m top_right_region = window[\u001b[32m50\u001b[39m:height, \u001b[32m0\u001b[39m:\u001b[38;5;28mint\u001b[39m(width * \u001b[32m0.35\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdist_box\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m     preprocessed_region = pre_process(top_right_region)\n\u001b[32m     19\u001b[39m     results = reader.readtext(preprocessed_region)\n",
      "\u001b[31mNameError\u001b[39m: name 'dist_box' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the main loop\n",
    "the_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
