{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Model Configuration: Default model type set to 'optimized'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dxcam_cpp as dxcam\n",
    "from src.utils.windowtools import (\n",
    "    fuzzy_window_search,\n",
    "    calculate_aspect_ratio,\n",
    "    check_aspect_ratio_validity,\n",
    "    get_monitor_number_from_coords,\n",
    "    normalise_coords_to_monitor\n",
    ")\n",
    "from src.utils.helpers import (\n",
    "    pre_process,\n",
    "    pre_process_distbox,\n",
    ")\n",
    "from src.models import get_model, get_default_model_type, get_model_info\n",
    "import matplotlib.pyplot as plt\n",
    "from easyocr import Reader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import threading\n",
    "import time as systime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 2560, 1392)]\n",
      "1\n",
      "The aspect ratio is reasonable.\n",
      "(0, 0, 2560, 1392)\n"
     ]
    }
   ],
   "source": [
    "coords = fuzzy_window_search(\"asphalt\")\n",
    "\n",
    "monitor_id = get_monitor_number_from_coords(coords)\n",
    "\n",
    "normalised_coords = normalise_coords_to_monitor(coords, monitor_id)\n",
    "\n",
    "aspect_ratio = calculate_aspect_ratio(normalised_coords)\n",
    "\n",
    "check_aspect_ratio_validity(aspect_ratio)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "camera = dxcam.create(device_idx=0, output_idx=monitor_id)\n",
    "capturing = True\n",
    "time = 0\n",
    "elapsed_ms = 0\n",
    "percentage = 0\n",
    "\n",
    "# Inference time tracking\n",
    "inference_times = []\n",
    "total_loops = 0\n",
    "avg_inference_time = 0\n",
    "\n",
    "reader = Reader(['en'], gpu=True)  # Still needed for DIST detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a frame from the camera\n",
    "window = camera.grab()\n",
    "\n",
    "# Extract coordinates from the coords variable\n",
    "x1, y1, x2, y2 = normalised_coords\n",
    "\n",
    "capture_coords = (x1, y1, x2, int(y1 + (y2 - y1) / 3.4))\n",
    "\n",
    "camera.start(region=capture_coords, target_fps=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing stopped\n"
     ]
    }
   ],
   "source": [
    "def start_capturing():\n",
    "    global capturing\n",
    "    capturing = True\n",
    "    print(\"Capturing started\")\n",
    "\n",
    "def stop_capturing():\n",
    "    global capturing\n",
    "    capturing = False\n",
    "    print(\"Capturing stopped\")\n",
    "\n",
    "def update_time_label():\n",
    "    time_label.config(text=f\"Time: {time}\")\n",
    "    elapsed_label.config(text=f\"Elapsed: {elapsed_ms:.2f} ms\")\n",
    "    percentage_label.config(text=f\"Percentage: {percentage}\")\n",
    "    avg_inference_label.config(text=f\"Avg Inference: {avg_inference_time:.2f} ms\")\n",
    "    # Schedule the next update in 100 ms\n",
    "    time_label.after(100, update_time_label)\n",
    "\n",
    "def create_ui():\n",
    "    global time_label, elapsed_label, percentage_label, avg_inference_label\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Capture Control\")\n",
    "\n",
    "    start_button = tk.Button(root, text=\"Start\", command=start_capturing, bg=\"green\", fg=\"white\", font=(\"Helvetica\", 16))\n",
    "    start_button.pack(pady=10)\n",
    "\n",
    "    stop_button = tk.Button(root, text=\"Stop\", command=stop_capturing, bg=\"red\", fg=\"white\", font=(\"Helvetica\", 16))\n",
    "    stop_button.pack(pady=10)\n",
    "\n",
    "    time_label = tk.Label(root, text=f\"Time: {time}\", font=(\"Helvetica\", 14))\n",
    "    time_label.pack(pady=10)\n",
    "\n",
    "    elapsed_label = tk.Label(root, text=f\"Elapsed: {elapsed_ms:.2f} ms\", font=(\"Helvetica\", 14))\n",
    "    elapsed_label.pack(pady=10)\n",
    "\n",
    "    percentage_label = tk.Label(root, text=f\"Percentage: {percentage}\", font=(\"Helvetica\", 14))\n",
    "    percentage_label.pack(pady=10)\n",
    "\n",
    "    avg_inference_label = tk.Label(root, text=f\"Avg Inference: {avg_inference_time:.2f} ms\", font=(\"Helvetica\", 14))\n",
    "    avg_inference_label.pack(pady=10)\n",
    "\n",
    "    # Start periodic UI updates in the main thread\n",
    "    update_time_label()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "ui_thread = threading.Thread(target=create_ui)\n",
    "ui_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Using default model type: 'optimized'\n",
      "Successfully loaded optimized model with optimized weights on cuda.\n",
      "Model architecture: OptimizedPercentageCNN\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# --- Load the Trained Model using centralized system ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Try to load the configured model first, with fallback options\n",
    "model = None\n",
    "model_name = \"unknown\"\n",
    "\n",
    "try:\n",
    "    # First try the centralized model system\n",
    "    model = get_model()\n",
    "    model_name = get_default_model_type()\n",
    "    \n",
    "    # Try to load the optimized model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('percentage_cnn_optimized.pth', map_location=device))\n",
    "        print(f\"Successfully loaded {model_name} model with optimized weights on {device}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Optimized weights not found, trying legacy weights...\")\n",
    "        model.load_state_dict(torch.load('percentage_cnn.pth', map_location=device))\n",
    "        print(f\"Successfully loaded {model_name} model with legacy weights on {device}.\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to load centralized model: {e}\")\n",
    "    \n",
    "    # Fallback to hardcoded model loading\n",
    "    try:\n",
    "        # Legacy SimpleCNN fallback\n",
    "        class SimpleCNN(nn.Module):\n",
    "            def __init__(self, num_classes=100):\n",
    "                super(SimpleCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "                self.fc1 = nn.Linear(32 * 16 * 16, 512)\n",
    "                self.fc2 = nn.Linear(512, num_classes)\n",
    "                self.relu = nn.ReLU()\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.conv1(x)))\n",
    "                x = self.pool(self.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 32 * 16 * 16)\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "        \n",
    "        model = SimpleCNN(num_classes=100).to(device)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('percentage_cnn_optimized.pth', map_location=device))\n",
    "            model_name = \"SimpleCNN (fallback with optimized weights)\"\n",
    "        except FileNotFoundError:\n",
    "            model.load_state_dict(torch.load('percentage_cnn.pth', map_location=device))\n",
    "            model_name = \"SimpleCNN (fallback with legacy weights)\"\n",
    "        print(f\"Successfully loaded fallback model on {device}.\")\n",
    "    except Exception as fallback_error:\n",
    "        print(f\"Fallback model loading also failed: {fallback_error}\")\n",
    "        print(\"Error: No model could be loaded. Please ensure model files are available.\")\n",
    "        model = None\n",
    "\n",
    "if model is not None:\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(f\"Model architecture: {model.__class__.__name__}\")\n",
    "    print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# --- Define Image Transforms ---\n",
    "# These must be the same as the transforms used during training\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "textarray = []\n",
    "dist_box = None\n",
    "\n",
    "# Create a directory for the dataset\n",
    "DATASET_DIR = \"dataset\"\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "# CNN confidence threshold - adjust this value based on your model's performance\n",
    "CONFIDENCE_THRESHOLD = 0.65  # Reset bounding box if confidence is below this\n",
    "\n",
    "def predict_with_cnn(image_array):\n",
    "    \"\"\"\n",
    "    Use the trained CNN to predict the percentage from an image array.\n",
    "    \n",
    "    Args:\n",
    "        image_array: numpy array of the preprocessed image\n",
    "        \n",
    "    Returns:\n",
    "        predicted_percentage: integer from 0-99, or None if prediction fails\n",
    "    \"\"\"\n",
    "    global inference_times, avg_inference_time\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"CNN model not loaded\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # Start timing inference\n",
    "        inference_start = systime.perf_counter()\n",
    "        \n",
    "        # Convert numpy array to PIL Image\n",
    "        pil_image = Image.fromarray(image_array)\n",
    "        \n",
    "        # Apply the same transforms used during training\n",
    "        tensor_image = data_transforms(pil_image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tensor_image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            confidence = torch.softmax(outputs, 1)[0][predicted].item()\n",
    "        \n",
    "        # End timing and record\n",
    "        inference_end = systime.perf_counter()\n",
    "        inference_time = (inference_end - inference_start) * 1000  # Convert to ms\n",
    "        \n",
    "        # Update inference time tracking\n",
    "        inference_times.append(inference_time)\n",
    "        if len(inference_times) > 100:  # Keep only last 100 measurements\n",
    "            inference_times.pop(0)\n",
    "        \n",
    "        # Calculate new average\n",
    "        new_avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "        \n",
    "        # Warning if inference time jumps significantly\n",
    "        if len(inference_times) > 10:  # Only warn after some history\n",
    "            if inference_time > avg_inference_time * 2:\n",
    "                print(f\"⚠️ Inference time spike: {inference_time:.2f}ms (avg: {avg_inference_time:.2f}ms)\")\n",
    "            elif inference_time < avg_inference_time * 0.5 and avg_inference_time > 1:\n",
    "                print(f\"📈 Inference time improvement: {inference_time:.2f}ms (avg: {avg_inference_time:.2f}ms)\")\n",
    "        \n",
    "        avg_inference_time = new_avg_inference_time\n",
    "            \n",
    "        return predicted.item(), confidence\n",
    "    except Exception as e:\n",
    "        print(f\"CNN prediction error: {e}\")\n",
    "        return None\n",
    "\n",
    "def the_loop():\n",
    "    global dist_box\n",
    "    global capturing\n",
    "    global textarray\n",
    "    global camera\n",
    "    global percentage\n",
    "    global elapsed_ms\n",
    "    global total_loops\n",
    "\n",
    "    # Start the loop\n",
    "    while capturing:\n",
    "        if capturing:\n",
    "            start_time = systime.perf_counter()\n",
    "            total_loops += 1\n",
    "            \n",
    "            window = camera.get_latest_frame()\n",
    "            height, width, _ = window.shape\n",
    "            top_right_region = window[50:height, 0:int(width * 0.35)]\n",
    "\n",
    "            if dist_box is None:\n",
    "                preprocessed_region = pre_process(top_right_region)\n",
    "                results = reader.readtext(preprocessed_region)\n",
    "                \n",
    "                dist_found = False\n",
    "                dist_bbox = None\n",
    "                dist_index = -1\n",
    "                \n",
    "                # Find DIST\n",
    "                for i, (bbox, text, confidence) in enumerate(results):\n",
    "                    if \"dist\" in text.lower() and not dist_found:\n",
    "                        dist_bbox = np.array(bbox)\n",
    "                        dist_index = i\n",
    "                        dist_found = True\n",
    "                \n",
    "                # If we found DIST, look for percentage\n",
    "                if dist_found:\n",
    "                    dist_x0, dist_y0 = np.min(dist_bbox[:, 0]), np.min(dist_bbox[:, 1])\n",
    "                    dist_x1, dist_y1 = np.max(dist_bbox[:, 0]), np.max(dist_bbox[:, 1])\n",
    "                    dist_center_y = (dist_y0 + dist_y1) / 2\n",
    "                    \n",
    "                    best_percentage_match = None\n",
    "                    best_score = 0\n",
    "                    \n",
    "                    # Look for percentage indicators with more flexible criteria\n",
    "                    for j, (bbox, text, confidence) in enumerate(results):\n",
    "                        if j == dist_index:  # Skip the DIST box itself\n",
    "                            continue\n",
    "                            \n",
    "                        bbox_array = np.array(bbox)\n",
    "                        nx0, ny0 = np.min(bbox_array[:, 0]), np.min(bbox_array[:, 1])\n",
    "                        nx1, ny1 = np.max(bbox_array[:, 0]), np.max(bbox_array[:, 1])\n",
    "                        bbox_center_y = (ny0 + ny1) / 2\n",
    "                        \n",
    "                        # More flexible matching criteria\n",
    "                        text_clean = text.strip().replace(' ', '').replace(',', '').replace('.', '')\n",
    "                        \n",
    "                        # Check if it looks like a percentage\n",
    "                        has_percent = '%' in text_clean\n",
    "                        has_numbers = any(char.isdigit() for char in text_clean)\n",
    "                        ends_with_7 = text_clean.endswith('7')  # Sometimes % is read as 7\n",
    "                        \n",
    "                        # Position criteria (more flexible)\n",
    "                        reasonable_y_distance = abs(bbox_center_y - dist_center_y) < 50\n",
    "                        to_the_right = nx0 > dist_x0\n",
    "                        reasonable_x_distance = (nx0 - dist_x1) < 200\n",
    "                        \n",
    "                        # Calculate a score for this match\n",
    "                        score = 0\n",
    "                        if has_percent:\n",
    "                            score += 50\n",
    "                        if has_numbers:\n",
    "                            score += 20\n",
    "                        if ends_with_7:\n",
    "                            score += 10\n",
    "                        if reasonable_y_distance:\n",
    "                            score += 30\n",
    "                        if to_the_right:\n",
    "                            score += 20\n",
    "                        if reasonable_x_distance:\n",
    "                            score += 10\n",
    "                        \n",
    "                        # Add confidence boost\n",
    "                        score += confidence * 10\n",
    "                        \n",
    "                        if score > best_score and score > 40:\n",
    "                            best_score = score\n",
    "                            best_percentage_match = (j, bbox, text, confidence)\n",
    "                    \n",
    "                    # If we found a good percentage match\n",
    "                    if best_percentage_match is not None:\n",
    "                        j, next_bbox, next_text, next_confidence = best_percentage_match\n",
    "                        \n",
    "                        # Calculate combined bounding box\n",
    "                        next_box = np.array(next_bbox)\n",
    "                        nx0, ny0 = np.min(next_box[:, 0]), np.min(next_box[:, 1])\n",
    "                        nx1, ny1 = np.max(next_box[:, 0]), np.max(next_box[:, 1])\n",
    "                        \n",
    "                        # Extend bounding box to include both with some padding\n",
    "                        x0 = int(min(dist_x0, nx0)) - 5\n",
    "                        y0 = int(min(dist_y0, ny0)) - 5\n",
    "                        x1 = int(max(dist_x1, nx1)) + 5\n",
    "                        y1 = int(max(dist_y1, ny1)) + 5\n",
    "                        \n",
    "                        # Ensure bounds are within image\n",
    "                        x0 = max(0, x0)\n",
    "                        y0 = max(0, y0)\n",
    "                        x1 = min(top_right_region.shape[1], x1)\n",
    "                        y1 = min(top_right_region.shape[0], y1)\n",
    "                    else:\n",
    "                        # Fallback: just use DIST box with some expansion\n",
    "                        x0 = int(dist_x0) - 10\n",
    "                        y0 = int(dist_y0) - 10\n",
    "                        x1 = int(dist_x1) + 100\n",
    "                        y1 = int(dist_y1) + 30\n",
    "                        \n",
    "                        # Ensure bounds are within image\n",
    "                        x0 = max(0, x0)\n",
    "                        y0 = max(0, y0)\n",
    "                        x1 = min(top_right_region.shape[1], x1)\n",
    "                        y1 = min(top_right_region.shape[0], y1)\n",
    "                    \n",
    "                    # Create the final bounding box\n",
    "                    dist_box = np.array([[x0, y0], [x1, y0], [x1, y1], [x0, y1]])\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # If we have the bounding box, crop the image\n",
    "            if dist_box is not None:\n",
    "                roi = top_right_region[int(dist_box[0][1]):int(dist_box[2][1]), int(dist_box[0][0]):int(dist_box[1][0])]\n",
    "                roi = roi[:, int(roi.shape[1] * 23 / 40):]\n",
    "\n",
    "                # Preprocess the cropped image for CNN\n",
    "                preprocessed_region = pre_process_distbox(roi, for_cnn=True)\n",
    "\n",
    "                # Use CNN for recognition\n",
    "                cnn_result = predict_with_cnn(preprocessed_region)\n",
    "\n",
    "            # Process CNN prediction\n",
    "            try:\n",
    "                if cnn_result is not None:\n",
    "                    predicted_percentage, confidence = cnn_result\n",
    "                    text2 = f\"{predicted_percentage}%\"\n",
    "                    \n",
    "                    print(f\"CNN Prediction: {predicted_percentage}% (confidence: {confidence:.3f})\")\n",
    "                    print(f\"Inference time: {inference_times[-1]:.2f}ms | Avg: {avg_inference_time:.2f}ms\")\n",
    "                    \n",
    "                    percentage = text2\n",
    "\n",
    "                    # Reset bounding box if confidence is too low\n",
    "                    if confidence < CONFIDENCE_THRESHOLD:\n",
    "                        dist_box = None\n",
    "                        print(f\"⚠️ Low confidence ({confidence:.3f}), resetting bounding box.\")\n",
    "                else:\n",
    "                    dist_box = None\n",
    "                    print(\"⚠️ CNN prediction failed, resetting bounding box.\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error processing CNN result: {e}\")\n",
    "                dist_box = None\n",
    "            \n",
    "            end_time = systime.perf_counter()\n",
    "            elapsed_ms = (end_time - start_time) * 1000\n",
    "            print(f\"Loop iteration: {elapsed_ms:.2f}ms (#{total_loops})\")\n",
    "\n",
    "            systime.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Inference time improvement: 3.59ms (avg: 7.23ms)\n",
      "CNN Prediction: 52% (confidence: 0.918)\n",
      "Inference time: 3.59ms | Avg: 7.21ms\n",
      "Loop iteration: 6.97ms (#1727)\n"
     ]
    }
   ],
   "source": [
    "# Run the main loop\n",
    "the_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
