{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b14340",
   "metadata": {},
   "source": [
    "# Dataset Amplification for Percentage Recognition\n",
    "\n",
    "This notebook amplifies the existing dataset by applying various transformations to create a more robust training set. The transformations include:\n",
    "\n",
    "1. **Scaling**: Resize images up to 55% larger or 60% smaller\n",
    "2. **Translation**: Shift images horizontally (±20px) or vertically (±10px)\n",
    "3. **Diagonal Shift**: Combined horizontal and vertical shifts (up to 10px each)\n",
    "4. **Aspect Distortion**: Squish/stretch by up to 5% while maintaining original aspect ratio\n",
    "5. **Zoom**: Zoom in up to 15% or zoom out up to 30%\n",
    "\n",
    "All transformations preserve the original image dimensions and aspect ratio using white padding, which works well since our images have white backgrounds with black text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c393e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce16d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset will be amplified by 2.5x\n",
      "Source directory: dataset_merged\n",
      "Output directory: dataset_amplified\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "SOURCE_DIR = \"dataset_merged\"\n",
    "OUTPUT_DIR = \"dataset_amplified\"\n",
    "\n",
    "# Amplification ratios (how many modified versions per original image)\n",
    "# 2.5x amplification focused on realistic UI positioning variations\n",
    "SCALING_RATIO = 0.3    # 30% of extra images: occasional size variations\n",
    "TRANSLATION_RATIO = 1.0  # 70% of extra images: horizontal/vertical UI positioning shifts\n",
    "DIAGONAL_RATIO = 0.2   # 13% of extra images: slight diagonal positioning\n",
    "DISTORTION_RATIO = 0    # Skip distortion (not realistic for this use case)\n",
    "ZOOM_RATIO = 0         # Skip zoom (scaling covers this)\n",
    "\n",
    "# Total amplification: 1 original + 1.5 modified = 2.5x dataset size (~16,250 images)\n",
    "# Distribution: 40% original data + 42% translation + 12% scaling + 6% diagonal\n",
    "print(f\"Dataset will be amplified by {1 + SCALING_RATIO + TRANSLATION_RATIO + DIAGONAL_RATIO + DISTORTION_RATIO + ZOOM_RATIO}x\")\n",
    "print(f\"Source directory: {SOURCE_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d547d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing filename parsing:\n",
      "  0pct_1.png -> label: 0, instance: 1\n",
      "    -> new name example: 0pct_1_scale1.png\n",
      "  0pct_10.png -> label: 0, instance: 10\n",
      "    -> new name example: 0pct_10_scale1.png\n",
      "  0pct_100.png -> label: 0, instance: 100\n",
      "    -> new name example: 0pct_100_scale1.png\n"
     ]
    }
   ],
   "source": [
    "def get_image_info(image_path):\n",
    "    \"\"\"Extract label and instance number from filename\"\"\"\n",
    "    filename = os.path.basename(image_path)\n",
    "    # Expected format: {label}pct_{instance}.png\n",
    "    parts = filename.replace('.png', '').split('_')\n",
    "    if len(parts) >= 2:\n",
    "        label = parts[0].replace('pct', '')\n",
    "        instance = parts[1]\n",
    "        return label, instance\n",
    "    return None, None\n",
    "\n",
    "def create_filename(label, instance, transform_type, transform_id):\n",
    "    \"\"\"Create a new filename for amplified images\"\"\"\n",
    "    return f\"{label}pct_{instance}_{transform_type}{transform_id}.png\"\n",
    "\n",
    "# Test the functions\n",
    "test_files = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.png')][:3]\n",
    "print(\"Testing filename parsing:\")\n",
    "for test_file in test_files:\n",
    "    label, instance = get_image_info(os.path.join(SOURCE_DIR, test_file))\n",
    "    print(f\"  {test_file} -> label: {label}, instance: {instance}\")\n",
    "    new_name = create_filename(label, instance, 'scale', 1)\n",
    "    print(f\"    -> new name example: {new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678c7117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image shape: (58, 107)\n",
      "Upscaled image shape: (58, 107)\n",
      "Downscaled image shape: (58, 107)\n"
     ]
    }
   ],
   "source": [
    "def apply_scaling(image, scale_factor):\n",
    "    \"\"\"Scale image up or down, then pad/crop to original size\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_h = int(h * scale_factor)\n",
    "    new_w = int(w * scale_factor)\n",
    "    \n",
    "    # Resize image\n",
    "    scaled = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    if scale_factor > 1.0:  # Image got larger, need to crop\n",
    "        # Calculate crop coordinates to center the crop\n",
    "        start_y = (new_h - h) // 2\n",
    "        start_x = (new_w - w) // 2\n",
    "        result = scaled[start_y:start_y + h, start_x:start_x + w]\n",
    "    else:  # Image got smaller, need to pad\n",
    "        # Calculate padding\n",
    "        pad_y = (h - new_h) // 2\n",
    "        pad_x = (w - new_w) // 2\n",
    "        \n",
    "        # Create white background\n",
    "        result = np.full((h, w), 255, dtype=np.uint8)\n",
    "        \n",
    "        # Place scaled image in center\n",
    "        result[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = scaled\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test scaling function\n",
    "if test_files:\n",
    "    test_image = cv2.imread(os.path.join(SOURCE_DIR, test_files[0]), cv2.IMREAD_GRAYSCALE)\n",
    "    print(f\"Original image shape: {test_image.shape}\")\n",
    "    \n",
    "    # Test upscaling\n",
    "    upscaled = apply_scaling(test_image, 1.3)\n",
    "    print(f\"Upscaled image shape: {upscaled.shape}\")\n",
    "    \n",
    "    # Test downscaling  \n",
    "    downscaled = apply_scaling(test_image, 0.7)\n",
    "    print(f\"Downscaled image shape: {downscaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f03d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing translation functions...\n",
      "Horizontal translation shape: (58, 107)\n",
      "Vertical translation shape: (58, 107)\n",
      "Diagonal shift shape: (58, 107)\n"
     ]
    }
   ],
   "source": [
    "def apply_translation(image, dx, dy):\n",
    "    \"\"\"Translate image by dx, dy pixels with white padding\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Create translation matrix\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    \n",
    "    # Apply translation with white border\n",
    "    translated = cv2.warpAffine(image, M, (w, h), borderValue=255)\n",
    "    \n",
    "    return translated\n",
    "\n",
    "def apply_diagonal_shift(image, dx, dy):\n",
    "    \"\"\"Apply diagonal shift (same as translation but with both dx and dy)\"\"\"\n",
    "    return apply_translation(image, dx, dy)\n",
    "\n",
    "# Test translation functions\n",
    "if test_files:\n",
    "    print(\"Testing translation functions...\")\n",
    "    \n",
    "    # Test horizontal translation\n",
    "    h_translated = apply_translation(test_image, 15, 0)\n",
    "    print(f\"Horizontal translation shape: {h_translated.shape}\")\n",
    "    \n",
    "    # Test vertical translation\n",
    "    v_translated = apply_translation(test_image, 0, -8)\n",
    "    print(f\"Vertical translation shape: {v_translated.shape}\")\n",
    "    \n",
    "    # Test diagonal shift\n",
    "    diagonal = apply_diagonal_shift(test_image, 7, 5)\n",
    "    print(f\"Diagonal shift shape: {diagonal.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05fd124c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing aspect distortion...\n",
      "Horizontally stretched shape: (58, 107)\n",
      "Vertically stretched shape: (58, 107)\n"
     ]
    }
   ],
   "source": [
    "def apply_aspect_distortion(image, x_factor, y_factor):\n",
    "    \"\"\"Apply slight aspect ratio distortion, then pad back to original ratio\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_w = int(w * x_factor)\n",
    "    new_h = int(h * y_factor)\n",
    "    \n",
    "    # Resize with distortion\n",
    "    distorted = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Create white background with original dimensions\n",
    "    result = np.full((h, w), 255, dtype=np.uint8)\n",
    "    \n",
    "    # Calculate centering offsets\n",
    "    offset_y = (h - new_h) // 2\n",
    "    offset_x = (w - new_w) // 2\n",
    "    \n",
    "    # Handle cases where distorted image might be larger than original\n",
    "    if new_h <= h and new_w <= w:\n",
    "        # Image fits, just center it\n",
    "        result[offset_y:offset_y + new_h, offset_x:offset_x + new_w] = distorted\n",
    "    else:\n",
    "        # Image is larger, need to crop it\n",
    "        crop_y = max(0, -offset_y)\n",
    "        crop_x = max(0, -offset_x)\n",
    "        place_y = max(0, offset_y)\n",
    "        place_x = max(0, offset_x)\n",
    "        \n",
    "        crop_h = min(new_h - crop_y, h - place_y)\n",
    "        crop_w = min(new_w - crop_x, w - place_x)\n",
    "        \n",
    "        result[place_y:place_y + crop_h, place_x:place_x + crop_w] = \\\n",
    "            distorted[crop_y:crop_y + crop_h, crop_x:crop_x + crop_w]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test distortion function\n",
    "if test_files:\n",
    "    print(\"Testing aspect distortion...\")\n",
    "    \n",
    "    # Test horizontal stretch\n",
    "    h_stretched = apply_aspect_distortion(test_image, 1.05, 0.95)\n",
    "    print(f\"Horizontally stretched shape: {h_stretched.shape}\")\n",
    "    \n",
    "    # Test vertical stretch\n",
    "    v_stretched = apply_aspect_distortion(test_image, 0.95, 1.05)\n",
    "    print(f\"Vertically stretched shape: {v_stretched.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcac86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing zoom functions...\n",
      "Zoomed in shape: (58, 107)\n",
      "Zoomed out shape: (58, 107)\n"
     ]
    }
   ],
   "source": [
    "def apply_zoom(image, zoom_factor):\n",
    "    \"\"\"Apply zoom in or out, maintaining original image size with white padding\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    if zoom_factor > 1.0:  # Zoom in\n",
    "        # Calculate the size of the region to extract from the original\n",
    "        extract_h = int(h / zoom_factor)\n",
    "        extract_w = int(w / zoom_factor)\n",
    "        \n",
    "        # Calculate center crop coordinates\n",
    "        start_y = (h - extract_h) // 2\n",
    "        start_x = (w - extract_w) // 2\n",
    "        \n",
    "        # Extract center region and resize to original size\n",
    "        cropped = image[start_y:start_y + extract_h, start_x:start_x + extract_w]\n",
    "        result = cv2.resize(cropped, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "    else:  # Zoom out\n",
    "        # Calculate new (smaller) dimensions\n",
    "        new_h = int(h * zoom_factor)\n",
    "        new_w = int(w * zoom_factor)\n",
    "        \n",
    "        # Resize image to smaller size\n",
    "        small = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Create white background and center the small image\n",
    "        result = np.full((h, w), 255, dtype=np.uint8)\n",
    "        offset_y = (h - new_h) // 2\n",
    "        offset_x = (w - new_w) // 2\n",
    "        result[offset_y:offset_y + new_h, offset_x:offset_x + new_w] = small\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test zoom function\n",
    "if test_files:\n",
    "    print(\"Testing zoom functions...\")\n",
    "    \n",
    "    # Test zoom in\n",
    "    zoomed_in = apply_zoom(test_image, 1.1)\n",
    "    print(f\"Zoomed in shape: {zoomed_in.shape}\")\n",
    "    \n",
    "    # Test zoom out\n",
    "    zoomed_out = apply_zoom(test_image, 0.8)\n",
    "    print(f\"Zoomed out shape: {zoomed_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724a1cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transforms:\n",
      "Scaling: []\n",
      "Translation: [('trans', 1, {'dx': -3, 'dy': -2})]\n",
      "Diagonal: []\n",
      "Distortion: []\n",
      "Zoom: []\n"
     ]
    }
   ],
   "source": [
    "def generate_scaling_transforms():\n",
    "    \"\"\"Generate scaling parameters\"\"\"\n",
    "    transforms = []\n",
    "    # 30% chance of scaling transform\n",
    "    if random.random() < SCALING_RATIO:\n",
    "        # Prefer smaller variations for UI elements\n",
    "        scale = random.uniform(0.85, 1.15)  # ±15% scaling\n",
    "        transforms.append(('scale', 1, {'scale_factor': scale}))\n",
    "    return transforms\n",
    "\n",
    "def generate_translation_transforms():\n",
    "    \"\"\"Generate translation parameters - focused on horizontal shifts\"\"\"\n",
    "    transforms = []\n",
    "    # Always apply translation (100% of images get this)\n",
    "    # 70% horizontal-focused, 30% vertical-focused\n",
    "    if random.random() < 0.7:\n",
    "        # Horizontal-focused shift (UI positioning)\n",
    "        dx = random.randint(-20, 20)  # Horizontal shift ±20px\n",
    "        dy = random.randint(-5, 5)    # Small vertical adjustment ±5px\n",
    "    else:\n",
    "        # Vertical-focused shift\n",
    "        dx = random.randint(-5, 5)    # Small horizontal adjustment ±5px\n",
    "        dy = random.randint(-10, 10)  # Vertical shift ±10px\n",
    "    \n",
    "    transforms.append(('trans', 1, {'dx': dx, 'dy': dy}))\n",
    "    return transforms\n",
    "\n",
    "def generate_diagonal_transforms():\n",
    "    \"\"\"Generate diagonal shift parameters\"\"\"\n",
    "    transforms = []\n",
    "    # 20% chance of diagonal shift\n",
    "    if random.random() < DIAGONAL_RATIO:\n",
    "        # Small diagonal shifts for UI element positioning\n",
    "        dx = random.randint(-8, 8)\n",
    "        dy = random.randint(-8, 8)\n",
    "        transforms.append(('diag', 1, {'dx': dx, 'dy': dy}))\n",
    "    return transforms\n",
    "\n",
    "def generate_distortion_transforms():\n",
    "    \"\"\"Generate aspect distortion parameters\"\"\"\n",
    "    return []  # Skip distortion\n",
    "\n",
    "def generate_zoom_transforms():\n",
    "    \"\"\"Generate zoom parameters\"\"\"\n",
    "    return []  # Skip zoom\n",
    "\n",
    "# Test transform generation\n",
    "print(\"Sample transforms:\")\n",
    "print(\"Scaling:\", generate_scaling_transforms())\n",
    "print(\"Translation:\", generate_translation_transforms())\n",
    "print(\"Diagonal:\", generate_diagonal_transforms())\n",
    "print(\"Distortion:\", generate_distortion_transforms())\n",
    "print(\"Zoom:\", generate_zoom_transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71025196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing processing on: 0pct_1.png\n",
      "Saved 2 images to test_amplification\n",
      "Generated files: ['0pct_1.png', '0pct_1_trans1.png']...\n",
      "Test completed and cleaned up.\n"
     ]
    }
   ],
   "source": [
    "def process_image(image_path, output_dir):\n",
    "    \"\"\"Process a single image with all transformations\"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Warning: Could not load {image_path}\")\n",
    "        return 0\n",
    "    \n",
    "    # Get image info\n",
    "    label, instance = get_image_info(image_path)\n",
    "    if label is None or instance is None:\n",
    "        print(f\"Warning: Could not parse filename {image_path}\")\n",
    "        return 0\n",
    "    \n",
    "    # Copy original image first\n",
    "    original_filename = f\"{label}pct_{instance}.png\"\n",
    "    original_path = os.path.join(output_dir, original_filename)\n",
    "    cv2.imwrite(original_path, image)\n",
    "    \n",
    "    saved_count = 1  # Count the original\n",
    "    \n",
    "    # Generate all transform parameters for this image\n",
    "    all_transforms = (\n",
    "        generate_scaling_transforms() +\n",
    "        generate_translation_transforms() +\n",
    "        generate_diagonal_transforms() +\n",
    "        generate_distortion_transforms() +\n",
    "        generate_zoom_transforms()\n",
    "    )\n",
    "    \n",
    "    # Apply each transformation\n",
    "    for transform_type, transform_id, params in all_transforms:\n",
    "        try:\n",
    "            if transform_type == 'scale':\n",
    "                transformed = apply_scaling(image, params['scale_factor'])\n",
    "            elif transform_type == 'trans':\n",
    "                transformed = apply_translation(image, params['dx'], params['dy'])\n",
    "            elif transform_type == 'diag':\n",
    "                transformed = apply_diagonal_shift(image, params['dx'], params['dy'])\n",
    "            elif transform_type == 'dist':\n",
    "                transformed = apply_aspect_distortion(image, params['x_factor'], params['y_factor'])\n",
    "            elif transform_type == 'zoom':\n",
    "                transformed = apply_zoom(image, params['zoom_factor'])\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Save transformed image\n",
    "            filename = create_filename(label, instance, transform_type, transform_id)\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(filepath, transformed)\n",
    "            saved_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error applying {transform_type} to {image_path}: {e}\")\n",
    "    \n",
    "    return saved_count\n",
    "\n",
    "# Test on a single image\n",
    "if test_files:\n",
    "    test_path = os.path.join(SOURCE_DIR, test_files[0])\n",
    "    print(f\"Testing processing on: {test_files[0]}\")\n",
    "    \n",
    "    # Create a temporary test directory\n",
    "    test_dir = \"test_amplification\"\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    saved = process_image(test_path, test_dir)\n",
    "    print(f\"Saved {saved} images to {test_dir}\")\n",
    "    \n",
    "    # List generated files\n",
    "    generated_files = sorted([f for f in os.listdir(test_dir) if f.endswith('.png')])\n",
    "    print(f\"Generated files: {generated_files[:5]}...\")  # Show first 5\n",
    "    \n",
    "    # Clean up test directory\n",
    "    shutil.rmtree(test_dir)\n",
    "    print(\"Test completed and cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1a70d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset amplification...\n",
      "==================================================\n",
      "Found 6543 images to process\n",
      "Expected output: ~58887 images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   1%|          | 69/6543 [00:00<00:09, 685.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 100/6543 images, saved 250 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   4%|▎         | 234/6543 [00:00<00:08, 786.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 200/6543 images, saved 496 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   5%|▍         | 318/6543 [00:00<00:07, 805.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 300/6543 images, saved 739 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   6%|▌         | 402/6543 [00:00<00:07, 816.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 400/6543 images, saved 987 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   7%|▋         | 486/6543 [00:00<00:07, 823.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 500/6543 images, saved 1235 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  10%|▉         | 653/6543 [00:00<00:07, 819.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 600/6543 images, saved 1491 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  11%|█         | 736/6543 [00:00<00:07, 819.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 700/6543 images, saved 1738 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  13%|█▎        | 818/6543 [00:01<00:07, 816.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 800/6543 images, saved 1989 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  14%|█▍        | 900/6543 [00:01<00:06, 808.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 900/6543 images, saved 2242 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  15%|█▍        | 981/6543 [00:01<00:06, 804.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1000/6543 images, saved 2496 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  17%|█▋        | 1145/6543 [00:01<00:06, 804.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1100/6543 images, saved 2750 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  19%|█▊        | 1226/6543 [00:01<00:06, 801.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1200/6543 images, saved 2996 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  20%|█▉        | 1307/6543 [00:01<00:06, 751.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1300/6543 images, saved 3246 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  21%|██        | 1383/6543 [00:01<00:07, 714.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1400/6543 images, saved 3494 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  24%|██▎       | 1546/6543 [00:01<00:06, 761.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1500/6543 images, saved 3745 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  25%|██▍       | 1629/6543 [00:02<00:06, 779.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1600/6543 images, saved 3992 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  26%|██▌       | 1708/6543 [00:02<00:06, 776.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1700/6543 images, saved 4253 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  27%|██▋       | 1787/6543 [00:02<00:06, 777.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1800/6543 images, saved 4508 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  30%|██▉       | 1944/6543 [00:02<00:05, 775.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 1900/6543 images, saved 4758 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  31%|███       | 2022/6543 [00:02<00:05, 761.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2000/6543 images, saved 5018 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  32%|███▏      | 2099/6543 [00:02<00:05, 758.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2100/6543 images, saved 5260 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  34%|███▍      | 2251/6543 [00:02<00:05, 750.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2200/6543 images, saved 5502 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  36%|███▌      | 2328/6543 [00:02<00:05, 755.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2300/6543 images, saved 5756 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  37%|███▋      | 2404/6543 [00:03<00:05, 740.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2400/6543 images, saved 6007 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  38%|███▊      | 2484/6543 [00:03<00:05, 753.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2500/6543 images, saved 6252 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  40%|████      | 2637/6543 [00:03<00:05, 753.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2600/6543 images, saved 6498 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  41%|████▏     | 2714/6543 [00:03<00:05, 757.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2700/6543 images, saved 6755 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  43%|████▎     | 2790/6543 [00:03<00:05, 748.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2800/6543 images, saved 7010 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  45%|████▍     | 2943/6543 [00:03<00:04, 754.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 2900/6543 images, saved 7260 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  46%|████▌     | 3020/6543 [00:03<00:04, 759.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3000/6543 images, saved 7511 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  47%|████▋     | 3096/6543 [00:04<00:04, 744.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3100/6543 images, saved 7767 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  50%|████▉     | 3246/6543 [00:04<00:04, 733.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3200/6543 images, saved 8017 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  51%|█████     | 3320/6543 [00:04<00:04, 732.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3300/6543 images, saved 8274 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  52%|█████▏    | 3394/6543 [00:04<00:04, 725.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3400/6543 images, saved 8515 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  53%|█████▎    | 3469/6543 [00:04<00:04, 731.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3500/6543 images, saved 8773 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  55%|█████▌    | 3626/6543 [00:04<00:03, 759.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3600/6543 images, saved 9016 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  57%|█████▋    | 3706/6543 [00:04<00:03, 769.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3700/6543 images, saved 9259 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  58%|█████▊    | 3784/6543 [00:04<00:03, 765.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3800/6543 images, saved 9518 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  60%|██████    | 3937/6543 [00:05<00:03, 754.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 3900/6543 images, saved 9778 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  61%|██████▏   | 4014/6543 [00:05<00:03, 758.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4000/6543 images, saved 10030 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  63%|██████▎   | 4090/6543 [00:05<00:03, 748.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4100/6543 images, saved 10290 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  64%|██████▎   | 4165/6543 [00:05<00:03, 726.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4200/6543 images, saved 10550 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  66%|██████▌   | 4310/6543 [00:05<00:03, 699.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4300/6543 images, saved 10809 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  67%|██████▋   | 4381/6543 [00:05<00:03, 691.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4400/6543 images, saved 11055 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  69%|██████▉   | 4528/6543 [00:05<00:02, 707.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4500/6543 images, saved 11309 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  70%|███████   | 4602/6543 [00:06<00:02, 714.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4600/6543 images, saved 11560 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  71%|███████▏  | 4676/6543 [00:06<00:02, 721.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4700/6543 images, saved 11820 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  74%|███████▎  | 4823/6543 [00:06<00:02, 700.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4800/6543 images, saved 12068 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  75%|███████▍  | 4894/6543 [00:06<00:02, 698.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 4900/6543 images, saved 12322 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  77%|███████▋  | 5043/6543 [00:06<00:02, 721.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5000/6543 images, saved 12565 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  78%|███████▊  | 5116/6543 [00:06<00:01, 722.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5100/6543 images, saved 12825 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  79%|███████▉  | 5193/6543 [00:06<00:01, 734.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5200/6543 images, saved 13077 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  82%|████████▏ | 5345/6543 [00:07<00:01, 742.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5300/6543 images, saved 13330 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  83%|████████▎ | 5420/6543 [00:07<00:01, 727.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5400/6543 images, saved 13577 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  84%|████████▍ | 5498/6543 [00:07<00:01, 741.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5500/6543 images, saved 13813 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  86%|████████▋ | 5654/6543 [00:07<00:01, 760.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5600/6543 images, saved 14060 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  88%|████████▊ | 5731/6543 [00:07<00:01, 759.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5700/6543 images, saved 14304 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  89%|████████▉ | 5807/6543 [00:07<00:01, 732.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5800/6543 images, saved 14545 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  90%|████████▉ | 5887/6543 [00:07<00:00, 752.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5900/6543 images, saved 14781 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  92%|█████████▏| 6046/6543 [00:08<00:00, 759.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6000/6543 images, saved 15017 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  94%|█████████▎| 6123/6543 [00:08<00:00, 758.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6100/6543 images, saved 15274 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  95%|█████████▍| 6202/6543 [00:08<00:00, 767.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6200/6543 images, saved 15514 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  96%|█████████▌| 6280/6543 [00:08<00:00, 770.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6300/6543 images, saved 15757 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  97%|█████████▋| 6358/6543 [00:08<00:00, 765.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6400/6543 images, saved 16008 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████▉| 6515/6543 [00:08<00:00, 758.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 6500/6543 images, saved 16250 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 6543/6543 [00:08<00:00, 753.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "AMPLIFICATION COMPLETE\n",
      "==================================================\n",
      "Processed: 6543 original images\n",
      "Generated: 16360 total images\n",
      "Failed: 0 images\n",
      "Amplification ratio: 2.5x\n",
      "Output directory: dataset_amplified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main amplification process\n",
    "print(\"Starting dataset amplification...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get all source images\n",
    "source_images = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.png')]\n",
    "total_images = len(source_images)\n",
    "\n",
    "print(f\"Found {total_images} images to process\")\n",
    "print(f\"Expected output: ~{total_images * 9} images\")\n",
    "print()\n",
    "\n",
    "# Process all images with progress bar\n",
    "total_saved = 0\n",
    "failed_count = 0\n",
    "\n",
    "for i, filename in enumerate(tqdm(source_images, desc=\"Processing images\")):\n",
    "    image_path = os.path.join(SOURCE_DIR, filename)\n",
    "    \n",
    "    try:\n",
    "        saved_count = process_image(image_path, OUTPUT_DIR)\n",
    "        total_saved += saved_count\n",
    "        \n",
    "        # Progress update every 100 images\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"\\nProcessed {i + 1}/{total_images} images, saved {total_saved} total\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nFailed to process {filename}: {e}\")\n",
    "        failed_count += 1\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"AMPLIFICATION COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Processed: {total_images} original images\")\n",
    "print(f\"Generated: {total_saved} total images\")\n",
    "print(f\"Failed: {failed_count} images\")\n",
    "print(f\"Amplification ratio: {total_saved / total_images:.1f}x\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46c7d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating output statistics...\n",
      "========================================\n",
      "Total output files: 16360\n",
      "\n",
      "Files by transformation type:\n",
      "  diagonal: 1291\n",
      "  original: 6543\n",
      "  scaling: 1983\n",
      "  translation: 6543\n",
      "\n",
      "Number of unique labels: 100\n",
      "\n",
      "Top 10 labels by count:\n",
      "  0%: 424 images\n",
      "  63%: 302 images\n",
      "  40%: 217 images\n",
      "  7%: 214 images\n",
      "  1%: 207 images\n",
      "  2%: 197 images\n",
      "  6%: 197 images\n",
      "  10%: 196 images\n",
      "  22%: 196 images\n",
      "  5%: 193 images\n",
      "\n",
      "Estimated total size: 9.9 MB\n",
      "Average file size: 0.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Verify output and generate statistics\n",
    "print(\"Generating output statistics...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Count files by type\n",
    "output_files = [f for f in os.listdir(OUTPUT_DIR) if f.endswith('.png')]\n",
    "transform_counts = Counter()\n",
    "label_counts = Counter()\n",
    "\n",
    "for filename in output_files:\n",
    "    # Count by transform type\n",
    "    if '_scale' in filename:\n",
    "        transform_counts['scaling'] += 1\n",
    "    elif '_trans' in filename:\n",
    "        transform_counts['translation'] += 1\n",
    "    elif '_diag' in filename:\n",
    "        transform_counts['diagonal'] += 1\n",
    "    elif '_dist' in filename:\n",
    "        transform_counts['distortion'] += 1\n",
    "    elif '_zoom' in filename:\n",
    "        transform_counts['zoom'] += 1\n",
    "    else:\n",
    "        transform_counts['original'] += 1\n",
    "    \n",
    "    # Count by label\n",
    "    label, _ = get_image_info(os.path.join(OUTPUT_DIR, filename))\n",
    "    if label:\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Total output files: {len(output_files)}\")\n",
    "print(\"\\nFiles by transformation type:\")\n",
    "for transform_type, count in sorted(transform_counts.items()):\n",
    "    print(f\"  {transform_type}: {count}\")\n",
    "\n",
    "print(f\"\\nNumber of unique labels: {len(label_counts)}\")\n",
    "print(\"\\nTop 10 labels by count:\")\n",
    "for label, count in label_counts.most_common(10):\n",
    "    print(f\"  {label}%: {count} images\")\n",
    "\n",
    "# Calculate disk space\n",
    "total_size = 0\n",
    "for filename in output_files[:100]:  # Sample first 100 files\n",
    "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "    total_size += os.path.getsize(filepath)\n",
    "\n",
    "avg_size = total_size / min(100, len(output_files))\n",
    "estimated_total_size = avg_size * len(output_files) / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"\\nEstimated total size: {estimated_total_size:.1f} MB\")\n",
    "print(f\"Average file size: {avg_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4d0ea",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The dataset amplification is now complete! Here's what was accomplished:\n",
    "\n",
    "### Transformations Applied:\n",
    "1. **Scaling**: Images resized up to 55% larger or 60% smaller\n",
    "2. **Translation**: Images shifted horizontally (±20px) or vertically (±10px)\n",
    "3. **Diagonal Shift**: Combined horizontal and vertical shifts (up to ±10px each)\n",
    "4. **Aspect Distortion**: Slight squishing/stretching by ±5%\n",
    "5. **Zoom**: Zoom in up to 15% or zoom out up to 30%\n",
    "\n",
    "### Key Features:\n",
    "- Original aspect ratios and dimensions preserved\n",
    "- White background padding maintains image consistency\n",
    "- Balanced amplification ratio (9x total dataset size)\n",
    "- Original images included to maintain core accuracy\n",
    "\n",
    "### Next Steps:\n",
    "1. Use the `dataset_amplified` folder for CNN training\n",
    "2. The amplified dataset should provide better robustness to real-world variations\n",
    "3. Monitor training performance and adjust amplification ratios if needed\n",
    "\n",
    "The amplified dataset maintains the majority of original images while providing sufficient variation to improve model robustness in production scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
