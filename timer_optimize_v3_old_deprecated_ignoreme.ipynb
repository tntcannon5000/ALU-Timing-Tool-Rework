{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dxcam_cpp as dxcam\n",
    "from src.utils.windowtools import (\n",
    "    fuzzy_window_search,\n",
    "    calculate_aspect_ratio,\n",
    "    check_aspect_ratio_validity,\n",
    "    get_monitor_number_from_coords,\n",
    "    normalise_coords_to_monitor\n",
    ")\n",
    "from src.utils.helpers import (\n",
    "    pre_process,\n",
    "    pre_process_distbox,\n",
    ")\n",
    "from src.models import get_model, get_default_model_type\n",
    "from easyocr import Reader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import threading\n",
    "import time as systime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = fuzzy_window_search(\"asphalt\")\n",
    "\n",
    "monitor_id = get_monitor_number_from_coords(coords)\n",
    "\n",
    "normalised_coords = normalise_coords_to_monitor(coords, monitor_id)\n",
    "\n",
    "aspect_ratio = calculate_aspect_ratio(normalised_coords)\n",
    "\n",
    "check_aspect_ratio_validity(aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading digit templates for timer recognition...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 210\u001b[39m\n\u001b[32m    207\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading digit templates for timer recognition...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m digit_templates = \u001b[43mload_digit_templates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(digit_templates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m digit templates for timer recognition\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mload_digit_templates\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03mLoad the manually created digit templates (0-9) from the processed directory.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m templates = {}\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m.path.exists(TEMPLATE_DIR):\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTemplate directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m templates\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# === DIGIT RECOGNITION USING TEMPLATE MATCHING ===\n",
    "\n",
    "# Configuration for template matching\n",
    "TEMPLATE_DIR = \"timer_templates\"  # Directory containing digit templates\n",
    "MATCH_THRESHOLD = 0.7  # Confidence threshold for template matching\n",
    "ITALIC_SHEAR_ANGLE = -15  # Degrees to correct italic text\n",
    "\n",
    "_clahe = None\n",
    "_shear_matrix = None\n",
    "\n",
    "def load_digit_templates():\n",
    "    \"\"\"\n",
    "    Load the manually created digit templates (0-9) from the processed directory.\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "    \n",
    "    if not os.path.exists(TEMPLATE_DIR):\n",
    "        print(f\"Template directory {TEMPLATE_DIR} not found!\")\n",
    "        return templates\n",
    "    \n",
    "    # Load digit templates (0-9)\n",
    "    for digit in range(10):\n",
    "        template_path = os.path.join(TEMPLATE_DIR, f\"{digit}.png\")\n",
    "        \n",
    "        if os.path.exists(template_path):\n",
    "            template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if template is not None:\n",
    "                templates[str(digit)] = template\n",
    "                print(f\"Loaded template for digit '{digit}' (size: {template.shape[1]}x{template.shape[0]})\")\n",
    "            else:\n",
    "                print(f\"Failed to load template: {template_path}\")\n",
    "        else:\n",
    "            print(f\"Template not found: {template_path}\")\n",
    "    \n",
    "    return templates\n",
    "\n",
    "def correct_italic_text(image, shear_angle_degrees=ITALIC_SHEAR_ANGLE):\n",
    "    \"\"\"\n",
    "    Correct italic text by applying inverse shear transformation.\n",
    "    \"\"\"\n",
    "    global _shear_matrix\n",
    "    height, width = image.shape\n",
    "    \n",
    "    if _shear_matrix is None:\n",
    "        shear_angle = np.radians(shear_angle_degrees)\n",
    "        shear_factor = -np.tan(shear_angle)\n",
    "        _shear_matrix = np.float32([[1, shear_factor, 0], [0, 1, 0]])\n",
    "    \n",
    "    new_width = int(width + abs(np.tan(np.radians(shear_angle_degrees)) * height))\n",
    "    \n",
    "    corrected = cv2.warpAffine(image, _shear_matrix, (new_width, height), \n",
    "                              borderMode=cv2.BORDER_CONSTANT, \n",
    "                              borderValue=255)\n",
    "    \n",
    "    return corrected\n",
    "\n",
    "def preprocess_timer_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess timer image: correct italics, enhance contrast, ensure binary.\n",
    "    \"\"\"\n",
    "    global _clahe\n",
    "    if _clahe is None:\n",
    "        _clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    \n",
    "    corrected = correct_italic_text(image)\n",
    "    enhanced = _clahe.apply(corrected)\n",
    "    denoised = cv2.medianBlur(enhanced, 3)\n",
    "    _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def match_digit_at_position(roi_image, templates, threshold=MATCH_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Match a character ROI against digit templates (0-9).\n",
    "    Returns the best matching digit and confidence.\n",
    "    \"\"\"\n",
    "    best_digit = None\n",
    "    best_confidence = 0\n",
    "    \n",
    "    if len(roi_image.shape) == 3:\n",
    "        roi_image = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    _, roi_binary = cv2.threshold(roi_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    scale_factors = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "    \n",
    "    for digit, template in templates.items():\n",
    "        max_confidence_for_digit = 0\n",
    "        \n",
    "        for scale_factor in scale_factors:\n",
    "            scaled_height = int(template.shape[0] * scale_factor)\n",
    "            scaled_width = int(template.shape[1] * scale_factor)\n",
    "            \n",
    "            if scaled_height > 0 and scaled_width > 0:\n",
    "                template_resized = cv2.resize(template, (scaled_width, scaled_height), \n",
    "                                            interpolation=cv2.INTER_CUBIC)\n",
    "                \n",
    "                if (roi_binary.shape[0] >= template_resized.shape[0] and \n",
    "                    roi_binary.shape[1] >= template_resized.shape[1]):\n",
    "                    result = cv2.matchTemplate(roi_binary, template_resized, cv2.TM_CCOEFF_NORMED)\n",
    "                    confidence = np.max(result)\n",
    "                elif (template_resized.shape[0] >= roi_binary.shape[0] and \n",
    "                      template_resized.shape[1] >= roi_binary.shape[1]):\n",
    "                    result = cv2.matchTemplate(template_resized, roi_binary, cv2.TM_CCOEFF_NORMED)\n",
    "                    confidence = np.max(result)\n",
    "                else:\n",
    "                    confidence = 0\n",
    "                \n",
    "                if confidence > max_confidence_for_digit:\n",
    "                    max_confidence_for_digit = confidence\n",
    "        \n",
    "        if max_confidence_for_digit > best_confidence:\n",
    "            best_confidence = max_confidence_for_digit\n",
    "            best_digit = digit\n",
    "    \n",
    "    if best_confidence >= threshold:\n",
    "        return best_digit, best_confidence\n",
    "    else:\n",
    "        return None, best_confidence\n",
    "\n",
    "def find_digit_regions(processed_image):\n",
    "    \"\"\"\n",
    "    Find potential digit regions in the processed image using contour detection.\n",
    "    Returns a list of (x, y, w, h) bounding boxes sorted left to right.\n",
    "    \"\"\"\n",
    "    inverted = cv2.bitwise_not(processed_image)\n",
    "    contours, _ = cv2.findContours(inverted, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    digit_regions = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        if (w >= 8 and h >= 12 and w <= 100 and h <= 100 and  \n",
    "            area > 50 and  \n",
    "            h/w >= 0.8 and h/w <= 4.0):\n",
    "            digit_regions.append((x, y, w, h))\n",
    "    \n",
    "    digit_regions.sort(key=lambda region: region[0])\n",
    "    \n",
    "    return digit_regions\n",
    "\n",
    "def extract_digits_from_timer(image, templates, debug=False):\n",
    "    \"\"\"\n",
    "    Extract only digits (0-9) from a timer image, ignoring punctuation.\n",
    "    Returns the digits string and total milliseconds.\n",
    "    \"\"\"\n",
    "    processed_image = preprocess_timer_image(image)\n",
    "    digit_regions = find_digit_regions(processed_image)\n",
    "    \n",
    "    recognized_digits = []\n",
    "    digit_details = []\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Found {len(digit_regions)} potential digit regions\")\n",
    "    \n",
    "    for i, (x, y, w, h) in enumerate(digit_regions):\n",
    "        padding = max(2, min(w, h) // 8)\n",
    "        x_start = max(0, x - padding)\n",
    "        y_start = max(0, y - padding)\n",
    "        x_end = min(processed_image.shape[1], x + w + padding)\n",
    "        y_end = min(processed_image.shape[0], y + h + padding)\n",
    "        \n",
    "        digit_roi = processed_image[y_start:y_end, x_start:x_end]\n",
    "        \n",
    "        if digit_roi.size > 0:\n",
    "            digit, confidence = match_digit_at_position(digit_roi, templates)\n",
    "            \n",
    "            if digit is not None:\n",
    "                recognized_digits.append(digit)\n",
    "                digit_details.append((digit, confidence, (x, y, w, h), digit_roi))\n",
    "                if debug:\n",
    "                    print(f\"  Region {i}: Digit '{digit}' (confidence: {confidence:.3f})\")\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"  Region {i}: No match (best confidence: {confidence:.3f})\")\n",
    "    \n",
    "    digits_only = ''.join(recognized_digits)\n",
    "    \n",
    "    return digits_only, digit_details, processed_image\n",
    "\n",
    "def convert_timer_to_milliseconds(timer_string):\n",
    "    \"\"\"\n",
    "    Convert timer string in format mmssxxx to total milliseconds.\n",
    "    mm = minutes (2 digits)\n",
    "    ss = seconds (2 digits) \n",
    "    xxx = milliseconds (3 digits)\n",
    "    \"\"\"\n",
    "    if not timer_string or len(timer_string) < 7:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if len(timer_string) >= 7:\n",
    "            timer_digits = timer_string[:7]\n",
    "            \n",
    "            minutes = int(timer_digits[0:2])\n",
    "            seconds = int(timer_digits[2:4])\n",
    "            milliseconds = int(timer_digits[4:7])\n",
    "            \n",
    "            total_ms = (minutes * 60 * 1000) + (seconds * 1000) + milliseconds\n",
    "            \n",
    "            return total_ms\n",
    "        else:\n",
    "            return None\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "print(\"Loading digit templates for timer recognition...\")\n",
    "digit_templates = load_digit_templates()\n",
    "print(f\"Loaded {len(digit_templates)} digit templates for timer recognition\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "camera = dxcam.create(device_idx=0, output_idx=monitor_id)\n",
    "capturing = True\n",
    "time = 0\n",
    "elapsed_ms = 0\n",
    "percentage = 0\n",
    "race_in_progress = False  # New variable to track race state\n",
    "\n",
    "# Inference time tracking\n",
    "inference_times = []\n",
    "total_loops = 0\n",
    "avg_inference_time = 0\n",
    "\n",
    "# Loop time tracking\n",
    "loop_times = []\n",
    "avg_loop_time = 0\n",
    "\n",
    "# Timer tracking variables\n",
    "current_timer_ms = 0  # Current timer in total milliseconds\n",
    "current_timer_display = \"00:00.000\"  # Formatted timer display\n",
    "\n",
    "reader = Reader(['en'], gpu=True)  # Still needed for DIST detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a frame from the camera\n",
    "window = camera.grab()\n",
    "\n",
    "# Extract coordinates from the coords variable\n",
    "x1, y1, x2, y2 = normalised_coords\n",
    "\n",
    "capture_coords = (x1, y1, x2, int(y1 + (y2 - y1) / 3.4))\n",
    "\n",
    "camera.start(region=capture_coords, target_fps=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_pin():\n",
    "    global root, is_pinned\n",
    "    is_pinned = not is_pinned\n",
    "    if is_pinned:\n",
    "        root.wm_attributes(\"-topmost\", True)\n",
    "        pin_button.config(text=\"📌 Unpin\", bg=\"#ff6b6b\")\n",
    "    else:\n",
    "        root.wm_attributes(\"-topmost\", False)\n",
    "        pin_button.config(text=\"📌 Pin\", bg=\"#4ecdc4\")\n",
    "\n",
    "def start_drag(event):\n",
    "    global start_x, start_y\n",
    "    start_x = event.x\n",
    "    start_y = event.y\n",
    "\n",
    "def on_drag(event):\n",
    "    global start_x, start_y\n",
    "    x = root.winfo_x() + (event.x - start_x)\n",
    "    y = root.winfo_y() + (event.y - start_y)\n",
    "    root.geometry(f\"+{x}+{y}\")\n",
    "\n",
    "def update_ui():\n",
    "    global time, elapsed_ms, percentage, avg_inference_time, inference_times\n",
    "    global current_timer_ms, current_timer_display, avg_loop_time\n",
    "    \n",
    "    # Update labels efficiently (only if values changed)\n",
    "    time_label.config(text=f\"Timer: {current_timer_display}\")\n",
    "    elapsed_label.config(text=f\"Loop: {elapsed_ms:.1f}ms\")\n",
    "    avg_loop_label.config(text=f\"Avg Loop: {avg_loop_time:.1f}ms\")\n",
    "    \n",
    "    # Progress bar and percentage\n",
    "    if percentage and percentage != \"0%\":\n",
    "        # Extract numeric value for progress bar\n",
    "        try:\n",
    "            progress_value = int(percentage.replace('%', ''))\n",
    "            progress_bar.config(value=progress_value)\n",
    "            progress_label.config(text=f\"{progress_value}%\")\n",
    "        except:\n",
    "            progress_value = 0\n",
    "            progress_bar.config(value=0)\n",
    "            progress_label.config(text=\"0%\")\n",
    "        \n",
    "        percentage_label.config(text=f\"Distance: {percentage}\", fg=\"#2ecc71\")\n",
    "    else:\n",
    "        progress_bar.config(value=0)\n",
    "        progress_label.config(text=\"--\")\n",
    "        percentage_label.config(text=\"Distance: --\", fg=\"#95a5a6\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    if inference_times:\n",
    "        current_inference = inference_times[-1] if inference_times else 0\n",
    "        inference_label.config(text=f\"Inference: {current_inference:.1f}ms\")\n",
    "        avg_inference_label.config(text=f\"Average: {avg_inference_time:.1f}ms\")\n",
    "    else:\n",
    "        inference_label.config(text=\"Inference: --\")\n",
    "        avg_inference_label.config(text=\"Average: --\")\n",
    "\n",
    "    # Schedule next update at 11ms (90 FPS) for ultra-responsive UI\n",
    "    root.after(11, update_ui)\n",
    "\n",
    "def create_ui():\n",
    "    global root, time_label, elapsed_label, percentage_label\n",
    "    global avg_inference_label, inference_label, pin_button, is_pinned\n",
    "    global progress_bar, progress_label, current_timer_display, avg_loop_label\n",
    "    global start_x, start_y\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.title(\"ALU Timing Tool\")\n",
    "    root.geometry(\"400x180\")\n",
    "    root.resizable(False, False)\n",
    "    \n",
    "    # Remove window decorations and make it borderless\n",
    "    root.overrideredirect(True)\n",
    "    \n",
    "    # Set up the window style\n",
    "    root.configure(bg=\"#2c3e50\", highlightbackground=\"#34495e\", highlightthickness=2)\n",
    "    \n",
    "    # Pin by default\n",
    "    is_pinned = True\n",
    "    root.wm_attributes(\"-topmost\", True)\n",
    "    \n",
    "    # Header with pin button - make it draggable\n",
    "    header_frame = tk.Frame(root, bg=\"#34495e\", height=30)\n",
    "    header_frame.pack(fill=\"x\")\n",
    "    header_frame.pack_propagate(False)\n",
    "    \n",
    "    # Bind drag events to header\n",
    "    header_frame.bind(\"<Button-1>\", start_drag)\n",
    "    header_frame.bind(\"<B1-Motion>\", on_drag)\n",
    "    \n",
    "    title_label = tk.Label(header_frame, text=\"ALU Timing Tool\", \n",
    "                          font=(\"Helvetica\", 11, \"bold\"), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    title_label.pack(side=\"left\", padx=10, pady=5)\n",
    "    \n",
    "    # Make title label draggable too\n",
    "    title_label.bind(\"<Button-1>\", start_drag)\n",
    "    title_label.bind(\"<B1-Motion>\", on_drag)\n",
    "    \n",
    "    pin_button = tk.Button(header_frame, text=\"📌 Unpin\", command=toggle_pin, \n",
    "                          bg=\"#ff6b6b\", fg=\"white\", font=(\"Helvetica\", 8),\n",
    "                          relief=\"flat\", padx=8, pady=2)\n",
    "    pin_button.pack(side=\"right\", padx=5, pady=5)\n",
    "    \n",
    "    # Main content area - single metrics panel\n",
    "    content_frame = tk.Frame(root, bg=\"#2c3e50\")\n",
    "    content_frame.pack(fill=\"both\", expand=True, padx=10, pady=5)\n",
    "    \n",
    "    # Metrics frame\n",
    "    metrics_frame = tk.Frame(content_frame, bg=\"#34495e\")\n",
    "    metrics_frame.pack(fill=\"both\", expand=True, pady=(0, 10))\n",
    "    \n",
    "    # Metrics title\n",
    "    metrics_title = tk.Label(metrics_frame, text=\"Performance Metrics\", \n",
    "                            font=(\"Helvetica\", 10, \"bold\"), fg=\"#bdc3c7\", bg=\"#34495e\")\n",
    "    metrics_title.pack(pady=(10, 10))\n",
    "    \n",
    "    # Loop timing\n",
    "    elapsed_label = tk.Label(metrics_frame, text=f\"Loop: {elapsed_ms:.1f}ms\", \n",
    "                            font=(\"Helvetica\", 10), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    elapsed_label.pack(pady=2)\n",
    "    \n",
    "    # Average loop timing\n",
    "    avg_loop_label = tk.Label(metrics_frame, text=\"Avg Loop: --\", \n",
    "                             font=(\"Helvetica\", 10), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    avg_loop_label.pack(pady=2)\n",
    "    \n",
    "    # Inference timing\n",
    "    inference_label = tk.Label(metrics_frame, text=\"Inference: --\", \n",
    "                              font=(\"Helvetica\", 10), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    inference_label.pack(pady=2)\n",
    "    \n",
    "    avg_inference_label = tk.Label(metrics_frame, text=\"Average: --\", \n",
    "                                  font=(\"Helvetica\", 10), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    avg_inference_label.pack(pady=2)\n",
    "    \n",
    "    # Timer\n",
    "    time_label = tk.Label(metrics_frame, text=f\"Timer: {current_timer_display}\", \n",
    "                         font=(\"Helvetica\", 10), fg=\"#ecf0f1\", bg=\"#34495e\")\n",
    "    time_label.pack(pady=2)\n",
    "    \n",
    "    # Distance percentage\n",
    "    percentage_label = tk.Label(metrics_frame, text=\"Distance: --\", \n",
    "                               font=(\"Helvetica\", 10, \"bold\"), fg=\"#95a5a6\", bg=\"#34495e\")\n",
    "    percentage_label.pack(pady=2)\n",
    "    \n",
    "    # Progress bar section at bottom\n",
    "    progress_frame = tk.Frame(content_frame, bg=\"#2c3e50\")\n",
    "    progress_frame.pack(fill=\"x\", pady=(0, 5))\n",
    "    \n",
    "    # Progress bar container with indicators\n",
    "    progress_container = tk.Frame(progress_frame, bg=\"#2c3e50\")\n",
    "    progress_container.pack(fill=\"x\", pady=5)\n",
    "    \n",
    "    # Start indicator (0%)\n",
    "    start_label = tk.Label(progress_container, text=\"0%\", \n",
    "                          font=(\"Helvetica\", 9, \"bold\"), fg=\"#ecf0f1\", bg=\"#2c3e50\")\n",
    "    start_label.pack(side=\"left\", padx=(0, 10))\n",
    "    \n",
    "    # Import ttk for progress bar\n",
    "    try:\n",
    "        from tkinter import ttk\n",
    "        style = ttk.Style()\n",
    "        style.theme_use('clam')\n",
    "        style.configure(\"Custom.Horizontal.TProgressbar\", \n",
    "                       background='#2ecc71',\n",
    "                       troughcolor='#34495e',\n",
    "                       borderwidth=0,\n",
    "                       lightcolor='#2ecc71',\n",
    "                       darkcolor='#2ecc71')\n",
    "        \n",
    "        progress_bar = ttk.Progressbar(progress_container, \n",
    "                                      style=\"Custom.Horizontal.TProgressbar\",\n",
    "                                      length=250, mode='determinate',\n",
    "                                      maximum=99)\n",
    "        progress_bar.pack(side=\"left\", fill=\"x\", expand=True, padx=(0, 10))\n",
    "        \n",
    "    except ImportError:\n",
    "        # Fallback if ttk is not available\n",
    "        progress_bar = tk.Frame(progress_container, bg=\"#34495e\", height=20)\n",
    "        progress_bar.pack(side=\"left\", fill=\"x\", expand=True, padx=(0, 10))\n",
    "    \n",
    "    # End indicator (race flag)\n",
    "    end_label = tk.Label(progress_container, text=\"🏁\", \n",
    "                        font=(\"Helvetica\", 12), fg=\"#ecf0f1\", bg=\"#2c3e50\")\n",
    "    end_label.pack(side=\"right\")\n",
    "    \n",
    "    # Progress value label (hidden, just for internal use)\n",
    "    progress_label = tk.Label(progress_container, text=\"--\", \n",
    "                             font=(\"Helvetica\", 1), fg=\"#2c3e50\", bg=\"#2c3e50\")\n",
    "    progress_label.pack_forget()  # Hide this label\n",
    "    \n",
    "    # Start the UI update loop\n",
    "    update_ui()\n",
    "    \n",
    "    # Make the window appear on top initially\n",
    "    root.lift()\n",
    "    root.focus_force()\n",
    "    \n",
    "    root.mainloop()\n",
    "\n",
    "# Initialize UI state variables\n",
    "is_pinned = True  # Start pinned\n",
    "root = None\n",
    "progress_bar = None\n",
    "progress_label = None\n",
    "start_x = 0\n",
    "start_y = 0\n",
    "\n",
    "ui_thread = threading.Thread(target=create_ui, daemon=True)\n",
    "ui_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Trained Model using centralized system ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Try to load the configured model first, with fallback options\n",
    "model = None\n",
    "model_name = \"unknown\"\n",
    "\n",
    "try:\n",
    "    # First try the centralized model system\n",
    "    model = get_model()\n",
    "    model_name = get_default_model_type()\n",
    "    \n",
    "    # Try to load the optimized model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('percentage_cnn_optimized.pth', map_location=device))\n",
    "    except FileNotFoundError:\n",
    "        model.load_state_dict(torch.load('percentage_cnn.pth', map_location=device))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Fallback to hardcoded model loading\n",
    "    try:\n",
    "        # Legacy SimpleCNN fallback\n",
    "        class SimpleCNN(nn.Module):\n",
    "            def __init__(self, num_classes=100):\n",
    "                super(SimpleCNN, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "                self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "                self.fc1 = nn.Linear(32 * 16 * 16, 512)\n",
    "                self.fc2 = nn.Linear(512, num_classes)\n",
    "                self.relu = nn.ReLU()\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.pool(self.relu(self.conv1(x)))\n",
    "                x = self.pool(self.relu(self.conv2(x)))\n",
    "                x = x.view(-1, 32 * 16 * 16)\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.fc2(x)\n",
    "                return x\n",
    "        \n",
    "        model = SimpleCNN(num_classes=100).to(device)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('percentage_cnn_optimized.pth', map_location=device))\n",
    "            model_name = \"SimpleCNN (fallback with optimized weights)\"\n",
    "        except FileNotFoundError:\n",
    "            model.load_state_dict(torch.load('percentage_cnn.pth', map_location=device))\n",
    "            model_name = \"SimpleCNN (fallback with legacy weights)\"\n",
    "    except Exception as fallback_error:\n",
    "        model = None\n",
    "\n",
    "if model is not None:\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # 🚀 PERFORMANCE OPTIMIZATIONS 🚀\n",
    "    \n",
    "    # 1. Enable cudnn benchmarking for consistent convolution algorithms\n",
    "    if device.type == 'cuda':\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # 2. Disable gradient computation globally (already in eval mode, but this is extra)\n",
    "    torch.set_grad_enabled(False)\n",
    "    \n",
    "    # 3. Try to compile the model with torch.jit for optimization\n",
    "    try:\n",
    "        # Create a dummy input for scripting\n",
    "        dummy_input = torch.randn(1, 1, 64, 64).to(device)\n",
    "        model = torch.jit.script(model)\n",
    "        \n",
    "        # Warm up the compiled model\n",
    "        for _ in range(5):\n",
    "            with torch.no_grad():\n",
    "                _ = model(dummy_input)\n",
    "        \n",
    "    except Exception as jit_error:\n",
    "        pass  # Continue with eager mode\n",
    "    \n",
    "    # 4. Set memory allocation strategy\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# --- Define Image Transforms ---\n",
    "# These must be the same as the transforms used during training\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "textarray = []\n",
    "dist_box = None\n",
    "\n",
    "# CNN confidence threshold - adjust this value based on your model's performance\n",
    "CONFIDENCE_THRESHOLD = 0.65  # Reset bounding box if confidence is below this\n",
    "\n",
    "# Pre-allocate tensor for reuse (optimization)\n",
    "_tensor_cache = None\n",
    "\n",
    "# Timer extraction variables - simplified\n",
    "timer_box = None\n",
    "timer_roi_coords = None  # Cache for timer ROI coordinates\n",
    "last_percentage = None\n",
    "current_timer = None\n",
    "\n",
    "def find_timer_roi_coords(frame):\n",
    "    \"\"\"\n",
    "    Find timer ROI coordinates using the blue mask (BGR 228,0,0).\n",
    "    Returns the coordinates for extracting the timer ROI.\n",
    "    \"\"\"\n",
    "    # Crop to right half of the original frame\n",
    "    height, width = frame.shape[:2]\n",
    "    right_half = frame[:, int(width * 0.5):]\n",
    "    right_half_offset = int(width * 0.5)\n",
    "    \n",
    "    # Create blue mask (BGR 228,0,0) with tolerance\n",
    "    tolerance = 30\n",
    "    target_bgr = np.array([228, 0, 0])\n",
    "    lower_bgr = np.maximum(target_bgr - tolerance, 0)\n",
    "    upper_bgr = np.minimum(target_bgr + tolerance, 255)\n",
    "    blue_mask = cv2.inRange(right_half, lower_bgr, upper_bgr)\n",
    "    \n",
    "    # Find contours in the blue mask\n",
    "    contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the largest contour (should be the timer box)\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        area = cv2.contourArea(largest_contour)\n",
    "        \n",
    "        # Validate size (timer should be reasonably sized)\n",
    "        if w > 50 and h > 20 and area > 1000:\n",
    "            # No padding\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w = min(right_half.shape[1] - x, w)\n",
    "            h = min(right_half.shape[0] - y, h)\n",
    "            \n",
    "            # Crop 10% from the left side\n",
    "            crop_left = int(w * 0.2)\n",
    "            \n",
    "            # Return coordinates relative to the full frame\n",
    "            return {\n",
    "                'x': x + right_half_offset + crop_left,\n",
    "                'y': y,\n",
    "                'w': w - crop_left,\n",
    "                'h': h\n",
    "            }\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_timer_roi_from_coords(frame, coords):\n",
    "    \"\"\"\n",
    "    Extract timer ROI using cached coordinates.\n",
    "    Returns a grayscale image with white background and black text.\n",
    "    \"\"\"\n",
    "    if coords is None:\n",
    "        return None\n",
    "    \n",
    "    # Crop to right half of the original frame\n",
    "    height, width = frame.shape[:2]\n",
    "    right_half = frame[:, int(width * 0.5):]\n",
    "    \n",
    "    # Create blue mask (BGR 228,0,0) with tolerance\n",
    "    tolerance = 30\n",
    "    target_bgr = np.array([228, 0, 0])\n",
    "    lower_bgr = np.maximum(target_bgr - tolerance, 0)\n",
    "    upper_bgr = np.minimum(target_bgr + tolerance, 255)\n",
    "    blue_mask = cv2.inRange(right_half, lower_bgr, upper_bgr)\n",
    "    \n",
    "    # Calculate coordinates relative to right_half\n",
    "    right_half_offset = int(width * 0.5)\n",
    "    rel_x = coords['x'] - right_half_offset\n",
    "    rel_y = coords['y']\n",
    "    rel_w = coords['w']\n",
    "    rel_h = coords['h']\n",
    "    \n",
    "    # Ensure coordinates are within bounds\n",
    "    rel_x = max(0, min(rel_x, right_half.shape[1] - 1))\n",
    "    rel_y = max(0, min(rel_y, right_half.shape[0] - 1))\n",
    "    rel_w = min(rel_w, right_half.shape[1] - rel_x)\n",
    "    rel_h = min(rel_h, right_half.shape[0] - rel_y)\n",
    "    \n",
    "    if rel_w > 0 and rel_h > 0:\n",
    "        # Extract the timer ROI from the blue mask\n",
    "        timer_roi_mask = blue_mask[rel_y:rel_y+rel_h, rel_x:rel_x+rel_w]\n",
    "        \n",
    "        # The blue mask has white pixels where blue background is detected\n",
    "        # We want white background with black text, so we use the mask directly\n",
    "        # Blue background areas become white (255), text areas become black (0)\n",
    "        timer_roi_corrected = timer_roi_mask.copy()\n",
    "        \n",
    "        return timer_roi_corrected\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_timer_roi(timer_roi):\n",
    "    \"\"\"\n",
    "    Process the timer ROI using template matching and convert to milliseconds.\n",
    "    Optimized for performance - no image saving, visualization, or OCR fallback.\n",
    "    \"\"\"\n",
    "    if timer_roi is None or timer_roi.size == 0:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Use template matching for digit recognition only\n",
    "        if digit_templates:\n",
    "            digits_string, digit_details, processed_img = extract_digits_from_timer(timer_roi, digit_templates, debug=False)\n",
    "            \n",
    "            # Convert to total milliseconds if we have enough digits\n",
    "            total_ms = convert_timer_to_milliseconds(digits_string)\n",
    "            \n",
    "            if digits_string:\n",
    "                # Print timer information when percentage changes\n",
    "                if total_ms is not None:\n",
    "                    minutes = total_ms // 60000\n",
    "                    seconds = (total_ms % 60000) // 1000\n",
    "                    milliseconds = total_ms % 1000\n",
    "                    print(f\"Timer at {last_percentage}: {digits_string} -> {minutes:02d}:{seconds:02d}.{milliseconds:03d} ({total_ms}ms)\")\n",
    "                else:\n",
    "                    print(f\"Timer at {last_percentage}: {digits_string} (conversion failed)\")\n",
    "                    \n",
    "                return digits_string\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def predict_with_cnn(image_array):\n",
    "    \"\"\"\n",
    "    Use the trained CNN to predict the percentage from an image array.\n",
    "    \n",
    "    Args:\n",
    "        image_array: numpy array of the preprocessed image\n",
    "        \n",
    "    Returns:\n",
    "        predicted_percentage: integer from 0-99, or None if prediction fails\n",
    "    \"\"\"\n",
    "    global inference_times, avg_inference_time, _tensor_cache\n",
    "    \n",
    "    if model is None:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # Start timing - more precise timing\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()  # Ensure all previous operations are complete\n",
    "        inference_start = systime.perf_counter()\n",
    "        \n",
    "        # Convert numpy array to PIL Image\n",
    "        pil_image = Image.fromarray(image_array)\n",
    "        \n",
    "        # Apply transforms\n",
    "        tensor_image = data_transforms(pil_image)\n",
    "        \n",
    "        # Reuse tensor cache if possible (optimization)\n",
    "        if _tensor_cache is None or _tensor_cache.shape[0] != 1:\n",
    "            _tensor_cache = tensor_image.unsqueeze(0).to(device, non_blocking=True)\n",
    "        else:\n",
    "            _tensor_cache.copy_(tensor_image.unsqueeze(0), non_blocking=True)\n",
    "        \n",
    "        # Make prediction with minimal overhead\n",
    "        outputs = model(_tensor_cache)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        confidence = torch.softmax(outputs, 1)[0][predicted].item()\n",
    "        \n",
    "        # End timing with synchronization\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()  # Wait for GPU operations to complete\n",
    "        inference_end = systime.perf_counter()\n",
    "        \n",
    "        inference_time = (inference_end - inference_start) * 1000  # Convert to ms\n",
    "        \n",
    "        # Update inference time tracking\n",
    "        inference_times.append(inference_time)\n",
    "        if len(inference_times) > 100:  # Keep only last 100 measurements\n",
    "            inference_times.pop(0)\n",
    "        \n",
    "        # Calculate new average\n",
    "        new_avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "        avg_inference_time = new_avg_inference_time\n",
    "            \n",
    "        return predicted.item(), confidence\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def the_loop():\n",
    "    global dist_box, capturing, textarray, camera, percentage, elapsed_ms, total_loops\n",
    "    global timer_box, timer_roi_coords, last_percentage, current_timer\n",
    "    global current_timer_ms, current_timer_display, loop_times, avg_loop_time\n",
    "\n",
    "    # Start the loop\n",
    "    while capturing:\n",
    "        if capturing:\n",
    "            # Start timing the entire loop\n",
    "            loop_start_time = systime.perf_counter()\n",
    "            total_loops += 1\n",
    "            \n",
    "            # Get latest frame\n",
    "            window = camera.get_latest_frame()\n",
    "            height, width, _ = window.shape\n",
    "            top_right_region = window[50:height, 0:int(width * 0.35)]\n",
    "\n",
    "            # Always update timer ROI coordinates to keep track of timer location\n",
    "            if timer_roi_coords is None:\n",
    "                timer_roi_coords = find_timer_roi_coords(window)\n",
    "\n",
    "            # OCR search when needed\n",
    "            current_percentage_value = None\n",
    "            if dist_box is None:\n",
    "                # Recalculate timer ROI coordinates when dist_box is None (re-searching for race)\n",
    "                timer_roi_coords = find_timer_roi_coords(window)\n",
    "                \n",
    "                preprocessed_region = pre_process(top_right_region)\n",
    "                results = reader.readtext(preprocessed_region)\n",
    "                \n",
    "                dist_found = False\n",
    "                dist_bbox = None\n",
    "                dist_index = -1\n",
    "                \n",
    "                # Find DIST\n",
    "                for i, (bbox, text, confidence) in enumerate(results):\n",
    "                    if \"dist\" in text.lower() and not dist_found:\n",
    "                        dist_bbox = np.array(bbox)\n",
    "                        dist_index = i\n",
    "                        dist_found = True\n",
    "                \n",
    "                # If we found DIST, look for percentage\n",
    "                if dist_found:\n",
    "                    dist_x0, dist_y0 = np.min(dist_bbox[:, 0]), np.min(dist_bbox[:, 1])\n",
    "                    dist_x1, dist_y1 = np.max(dist_bbox[:, 0]), np.max(dist_bbox[:, 1])\n",
    "                    dist_center_y = (dist_y0 + dist_y1) / 2\n",
    "                    \n",
    "                    best_percentage_match = None\n",
    "                    best_score = 0\n",
    "                    \n",
    "                    # Look for percentage indicators with more flexible criteria\n",
    "                    for j, (bbox, text, confidence) in enumerate(results):\n",
    "                        if j == dist_index:  # Skip the DIST box itself\n",
    "                            continue\n",
    "                            \n",
    "                        bbox_array = np.array(bbox)\n",
    "                        nx0, ny0 = np.min(bbox_array[:, 0]), np.min(bbox_array[:, 1])\n",
    "                        nx1, ny1 = np.max(bbox_array[:, 0]), np.max(bbox_array[:, 1])\n",
    "                        bbox_center_y = (ny0 + ny1) / 2\n",
    "                        \n",
    "                        # More flexible matching criteria\n",
    "                        text_clean = text.strip().replace(' ', '').replace(',', '').replace('.', '')\n",
    "                        \n",
    "                        # Check if it looks like a percentage\n",
    "                        has_percent = '%' in text_clean\n",
    "                        has_numbers = any(char.isdigit() for char in text_clean)\n",
    "                        ends_with_7 = text_clean.endswith('7')  # Sometimes % is read as 7\n",
    "                        \n",
    "                        # Position criteria (more flexible)\n",
    "                        reasonable_y_distance = abs(bbox_center_y - dist_center_y) < 50\n",
    "                        to_the_right = nx0 > dist_x0\n",
    "                        reasonable_x_distance = (nx0 - dist_x1) < 200\n",
    "                        \n",
    "                        # Calculate a score for this match\n",
    "                        score = 0\n",
    "                        if has_percent:\n",
    "                            score += 50\n",
    "                        if has_numbers:\n",
    "                            score += 20\n",
    "                        if ends_with_7:\n",
    "                            score += 10\n",
    "                        if reasonable_y_distance:\n",
    "                            score += 30\n",
    "                        if to_the_right:\n",
    "                            score += 20\n",
    "                        if reasonable_x_distance:\n",
    "                            score += 10\n",
    "                        \n",
    "                        # Add confidence boost\n",
    "                        score += confidence * 10\n",
    "                        \n",
    "                        if score > best_score and score > 40:\n",
    "                            best_score = score\n",
    "                            best_percentage_match = (j, bbox, text, confidence)\n",
    "                    \n",
    "                    # If we found a good percentage match\n",
    "                    if best_percentage_match is not None:\n",
    "                        j, next_bbox, next_text, next_confidence = best_percentage_match\n",
    "                        \n",
    "                        # Calculate combined bounding box\n",
    "                        next_box = np.array(next_bbox)\n",
    "                        nx0, ny0 = np.min(next_box[:, 0]), np.min(next_box[:, 1])\n",
    "                        nx1, ny1 = np.max(next_box[:, 0]), np.max(next_box[:, 1])\n",
    "                        \n",
    "                        # Extend bounding box to include both with some padding\n",
    "                        x0 = int(min(dist_x0, nx0)) - 5\n",
    "                        y0 = int(min(dist_y0, ny0)) - 5\n",
    "                        x1 = int(max(dist_x1, nx1)) + 5\n",
    "                        y1 = int(max(dist_y1, ny1)) + 5\n",
    "                        \n",
    "                        # Ensure bounds are within image\n",
    "                        x0 = max(0, x0)\n",
    "                        y0 = max(0, y0)\n",
    "                        x1 = min(top_right_region.shape[1], x1)\n",
    "                        y1 = min(top_right_region.shape[0], y1)\n",
    "                    else:\n",
    "                        # Fallback: just use DIST box with some expansion\n",
    "                        x0 = int(dist_x0) - 10\n",
    "                        y0 = int(dist_y0) - 10\n",
    "                        x1 = int(dist_x1) + 100\n",
    "                        y1 = int(dist_y1) + 30\n",
    "                        \n",
    "                        # Ensure bounds are within image\n",
    "                        x0 = max(0, x0)\n",
    "                        y0 = max(0, y0)\n",
    "                        x1 = min(top_right_region.shape[1], x1)\n",
    "                        y1 = min(top_right_region.shape[0], y1)\n",
    "                    \n",
    "                    # Create the final bounding box\n",
    "                    dist_box = np.array([[x0, y0], [x1, y0], [x1, y1], [x0, y1]])\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # CNN prediction\n",
    "            cnn_result = None\n",
    "            if dist_box is not None:\n",
    "                roi = top_right_region[int(dist_box[0][1]):int(dist_box[2][1]), int(dist_box[0][0]):int(dist_box[1][0])]\n",
    "                roi = roi[:, int(roi.shape[1] * 23 / 40):]\n",
    "\n",
    "                # Preprocess the cropped image for CNN\n",
    "                preprocessed_region = pre_process_distbox(roi, for_cnn=True)\n",
    "\n",
    "                # Use CNN for recognition\n",
    "                cnn_result = predict_with_cnn(preprocessed_region)\n",
    "\n",
    "            # Process CNN prediction and determine if we need to extract timer\n",
    "            percentage_changed = False\n",
    "            try:\n",
    "                if cnn_result is not None:\n",
    "                    predicted_percentage, confidence = cnn_result\n",
    "                    text2 = f\"{predicted_percentage}%\"\n",
    "                    current_percentage_value = predicted_percentage\n",
    "                    \n",
    "                    # Check if percentage changed\n",
    "                    if last_percentage != predicted_percentage:\n",
    "                        percentage_changed = True\n",
    "                        last_percentage = predicted_percentage\n",
    "                        print(f\"Percentage changed to: {predicted_percentage}%\")\n",
    "                    \n",
    "                    percentage = text2\n",
    "\n",
    "                    # Reset bounding box if confidence is too low\n",
    "                    if confidence < CONFIDENCE_THRESHOLD:\n",
    "                        dist_box = None\n",
    "                else:\n",
    "                    dist_box = None\n",
    "            except Exception as e:\n",
    "                dist_box = None\n",
    "\n",
    "            # Timer extraction only when percentage changes\n",
    "            if percentage_changed and timer_roi_coords is not None:\n",
    "                # Percentage increased - extract timer at this milestone\n",
    "                timer_roi = extract_timer_roi_from_coords(window, timer_roi_coords)\n",
    "                if timer_roi is not None:\n",
    "                    extracted_timer = process_timer_roi(timer_roi)\n",
    "                    if extracted_timer:\n",
    "                        current_timer = extracted_timer\n",
    "                        \n",
    "                        # Convert to milliseconds and update display\n",
    "                        timer_ms = convert_timer_to_milliseconds(extracted_timer)\n",
    "                        if timer_ms is not None:\n",
    "                            current_timer_ms = timer_ms\n",
    "                            # Format for display: MM:SS.mmm\n",
    "                            minutes = timer_ms // 60000\n",
    "                            seconds = (timer_ms % 60000) // 1000\n",
    "                            milliseconds = timer_ms % 1000\n",
    "                            current_timer_display = f\"{minutes:02d}:{seconds:02d}.{milliseconds:03d}\"\n",
    "            \n",
    "            # End timing the entire loop\n",
    "            loop_end_time = systime.perf_counter()\n",
    "            elapsed_ms = (loop_end_time - loop_start_time) * 1000\n",
    "            \n",
    "            # Update loop time tracking with running average (30 samples)\n",
    "            loop_times.append(elapsed_ms)\n",
    "            if len(loop_times) > 30:  # Keep last 30 measurements for running average\n",
    "                loop_times.pop(0)\n",
    "            \n",
    "            # Calculate new average loop time\n",
    "            avg_loop_time = sum(loop_times) / len(loop_times)\n",
    "\n",
    "            systime.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main loop\n",
    "the_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
